{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39bb3e23",
   "metadata": {},
   "source": [
    "# 데이터 입력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8834241d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋을 호출합니다...with ID: b37f0c9413eeb7c45f6fe31cbe3a41ef\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Meta_API_call' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 15\u001b[39m\n\u001b[32m     13\u001b[39m svc_id = \u001b[38;5;28minput\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m데이터셋 id :\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;66;03m# b37f0c9413eeb7c45f6fe31cbe3a41ef\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m데이터셋을 호출합니다...with ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msvc_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m data = \u001b[43mMeta_API_call\u001b[49m(svc_id)\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mtype\u001b[39m(data)) \u001b[38;5;66;03m# type: dict\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'Meta_API_call' is not defined"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from dotenv import load_dotenv # 입력 파트 종합본에 빼둘 것.\n",
    "load_dotenv(override=True)\n",
    "\n",
    "max_invalid = 4\n",
    "invalid_count = 0\n",
    "\n",
    "while True:\n",
    "    choice = input(\"입력데이터 선택\\n 1. 데이터셋  2. 논문\\n숫자(1 또는 2)를 입력하세요: \").strip()\n",
    "\n",
    "    if choice == \"1\":\n",
    "        # 데이터셋 호출 API\n",
    "        svc_id = input(\"데이터셋 id :\") # b37f0c9413eeb7c45f6fe31cbe3a41ef\n",
    "        print(f\"데이터셋을 호출합니다...with ID: {svc_id}\")\n",
    "        data = Meta_API_call(svc_id)\n",
    "        print(type(data)) # type: dict\n",
    "        break\n",
    "    elif choice == \"2\":\n",
    "        # 논문 호출 API\n",
    "        print(\"논문을 호출합니다...\")\n",
    "        pass # 논문  호출 API\n",
    "        break\n",
    "    else:\n",
    "        invalid_count += 1\n",
    "        remaining = max_invalid - invalid_count\n",
    "        if remaining <= 0:\n",
    "            print(\"입력 오류가 너무 많아 프로그램을 종료합니다.\")\n",
    "            sys.exit(1)\n",
    "        else:\n",
    "            print(f\"잘못된 입력입니다. {remaining}번 남았습니다. 다시 입력해주세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9857ef74",
   "metadata": {},
   "source": [
    "## 연구데이터 메타정보 조회 API(함수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a80aabe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(override=True)\n",
    "\n",
    "def DATA_browse(API_KEY, svc_id):\n",
    "    API_KEY = os.getenv(\"DATAON_META_API_KEY\")\n",
    "    assert API_KEY and API_KEY.strip(), \"환경변수(DATAON_META_API_KEY)가 비어있어요!\"\n",
    "\n",
    "    url = \"https://dataon.kisti.re.kr/rest/api/search/dataset/\"+svc_id\n",
    "    params = {\"key\": API_KEY}\n",
    "\n",
    "    # print(\"🔎 호출 URL 미리보기:\", requests.Request('GET', url, params=params).prepare().url)\n",
    "    res = requests.get(url, params=params, timeout=20)\n",
    "    print(\"HTTP\", res.status_code)\n",
    "    data = res.json()\n",
    "    print(data)\n",
    "    print(len(data['records']))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aae44a5",
   "metadata": {},
   "source": [
    "## 검색 노드(함수)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be869b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 호출 URL 미리보기: https://dataon.kisti.re.kr/rest/api/search/dataset/?key=D62EA22E8D9BBAFEFA15D7A0F39FD79F&query=korean+text&from=0&size=5\n",
      "HTTP 200\n",
      "{'response': {'elapsed time': '79 ms', 'status': '200', 'message': 'OK', 'total count': 28, 'type': 'json', 'key': 'D62EA22E8D9BBAFEFA15D7A0F39FD79F', 'query': 'korean text', 'from': 0, 'size': 5}, 'records': [{'svc_id': '2a8dadd5a1fb22affc1db8a345d66de4', 'ctlg_type': '02', 'dataset_type': '02', 'ctlg_type_pc': 'dataset', 'dataset_type_pc': '해외', 'dataset_pub_dt_pc': '2024', 'dataset_access_type_pc': '공개', 'file_yn_pc': '랜딩페이지이동', 'dataset_cc_license_pc': 'none', 'dataset_main_lang_pc': 'English', 'dataset_sub_lang_pc': 'none', 'cltfm_pc': 'ARDC', 'dataset_title_kor': '', 'dataset_title_etc_main': 'Weak Force 3', 'dataset_title_etc_sub': '', 'dataset_expl_kor': '', 'dataset_expl_etc_main': 'Research background: There has been a significant rise in group-based and collective art practice that challenges conventional methodologies and ideas of individual authorship in art. These enterprises approach art as an expanded form of intellectual activity by capitalizing on group dynamics and collective research. Research contribution: The Weak Force 3 builds upon previous iterations of Weak Force projects by the UFT collaborative group. The artists produced a sound and text installation in response to highly disruptive building works that were occurring next door to Zero Gallery at the time. A high-fidelity sound recording of drilling, pile driving and small-scale explosions from the construction site were resituated back into the gallery space through large-scale speakers. Gallery visitors were given the opportunity to switch the sound off or on by pushing an interactive foot pedal. This sound component was accompanied by contemporary Korean and Mandarin vinyl text, which was adhered to the walls and floor of the gallery. All texts referred to sound either metaphorically, metonymically or literally. Professor Suh Yongsun executed a painted text work on the gallery floor during the opening event, which discussed sound in the context of Confucian philosophy. Research significance: The significance of this research is that group-based practice was used to extend and combine the practices of eight artists working across five different continents. The artist¿s created a site-responsive installation that directly addressed the situation at hand, turning a situation of apparent adversity into a creative discourse.', 'dataset_expl_etc_sub': '', 'dataset_kywd_kor': '', 'dataset_kywd_etc_main': '', 'dataset_kywd_etc_sub': '', 'cltfm_kor': '', 'cltfm_etc': 'ARDC', 'dataset_data_loc': '{coordinates:[0.0,0.0],type:point}', 'dataset_lndgpg': 'https://doi.org/10.25439/rmt.27346197.v1', 'dataset_lndgpg_img': '', 'dataset_lndgpg_thum': '', 'dataset_doi': 'https://doi.org/10.25439/rmt.27346197.v1', 'dataset_etc_attr': '', 'dataset_regist_dt': '2025-04-21 17:39:55', 'dataset_creat_dt': '2024-10-30', 'dataset_mod_dt': '0001-01-01 00:00:00', 'dataset_mnsb_pc': ['Not Assigned'], 'file_frmt_pc': ['none'], 'pjt_prfrm_org_pc': ['none'], 'ministry_pc': ['none'], 'dataset_creator_kor': [], 'dataset_creator_etc_main': [], 'dataset_creator_etc_sub': [], 'pjt_prfrm_org_kor': [], 'pjt_prfrm_org_etc': [], 'ministry_kor': [], 'ministry_etc': [], 'pjt_nm_kor': [], 'pjt_nm_etc': [], 'pjt_mngr_kor': [], 'pjt_mngr_etc': [], 'dataset_cntrbtr_kor': [], 'dataset_cntrbtr_etc': [], 'dataset_pblshr': [], 'dataset_pric': []}, {'svc_id': 'b37f0c9413eeb7c45f6fe31cbe3a41ef', 'ctlg_type': '02', 'dataset_type': '02', 'ctlg_type_pc': 'dataset', 'dataset_type_pc': '해외', 'dataset_pub_dt_pc': '2024', 'dataset_access_type_pc': '공개', 'file_yn_pc': '랜딩페이지이동', 'dataset_cc_license_pc': 'none', 'dataset_main_lang_pc': 'English', 'dataset_sub_lang_pc': 'none', 'cltfm_pc': 'ARDC', 'dataset_title_kor': '', 'dataset_title_etc_main': 'Architectural Urbanism: Melbourne/Seoul - KTA projects', 'dataset_title_etc_sub': '', 'dataset_expl_kor': '', 'dataset_expl_etc_main': \"BACKGROUND: 'Architectural Urbanism: Melbourne/Seoul' was a two-city exhibition funded by RMIT University and the Korean National University, supported by the Australian Government through the Australian International Cultural Council. Kerstin Thompson Architecture (KTA) showed five works - Carrum Downs Police Station, MUMA Gallery, Lake Conneware House, Napier Street Housing and Royal Botanic Gardens Visitor Centre - as one of ten architectural firms (5 from Melbourne, 5 from Seoul) selected to exhibit. The exhibited work included large scale photographs, working drawings and exegetical text. CONTRIBUTION: The exhibition explored architectural approaches that worked 'within the city rather than upon it', architecture that 'intervenes and inserts, rather than overlays or eradicates'. Within this context, the public projects exhibited by KTA explore relationships between interior and exterior, building and street, and the existing and the new. This draws on Thompson's ongoing practice and design research focussing on architecture as a civic endeavour, forging connections between buildings, their surroundings and the people who inhabit them. SIGNIFICANCE: 'Architectural Urbanism' was an international, cross institutional exhibition that received external funding, evidencing significance for the selected works by the 10 participating practices. In Seoul, the exhibition was opened by the deputy Australian Ambassador. The Melbourne exhibition was reviewed in Architecture Australia (AA). These KTA projects have also received multiple awards and media attention including four AIA (Australian Institute of Architects) Victorian Architecture Awards, an IDEA (Interior Design Excellence Awards) award, three book features, critical reviews in AA, and articles in SMH, The Australian, Broadsheet and Archdaily.\", 'dataset_expl_etc_sub': '', 'dataset_kywd_kor': '', 'dataset_kywd_etc_main': '', 'dataset_kywd_etc_sub': '', 'cltfm_kor': '', 'cltfm_etc': 'ARDC', 'dataset_data_loc': '{coordinates:[0.0,0.0],type:point}', 'dataset_lndgpg': 'https://doi.org/10.25439/rmt.27353883.v1', 'dataset_lndgpg_img': '', 'dataset_lndgpg_thum': '', 'dataset_doi': 'https://doi.org/10.25439/rmt.27353883.v1', 'dataset_etc_attr': '', 'dataset_regist_dt': '2025-04-21 12:02:59', 'dataset_creat_dt': '2024-10-30', 'dataset_mod_dt': '0001-01-01 00:00:00', 'dataset_mnsb_pc': ['Not Assigned'], 'file_frmt_pc': ['none'], 'pjt_prfrm_org_pc': ['none'], 'ministry_pc': ['none'], 'dataset_creator_kor': [], 'dataset_creator_etc_main': [], 'dataset_creator_etc_sub': [], 'pjt_prfrm_org_kor': [], 'pjt_prfrm_org_etc': [], 'ministry_kor': [], 'ministry_etc': [], 'pjt_nm_kor': [], 'pjt_nm_etc': [], 'pjt_mngr_kor': [], 'pjt_mngr_etc': [], 'dataset_cntrbtr_kor': [], 'dataset_cntrbtr_etc': [], 'dataset_pblshr': [], 'dataset_pric': []}, {'svc_id': '6e9bbf90560c0236aa9c1ffdabc51b4f', 'ctlg_type': '02', 'dataset_type': '02', 'ctlg_type_pc': 'dataset', 'dataset_type_pc': '해외', 'dataset_pub_dt_pc': '2024', 'dataset_access_type_pc': '공개', 'file_yn_pc': '랜딩페이지이동', 'dataset_cc_license_pc': 'CC-BY-4.0', 'dataset_main_lang_pc': 'English', 'dataset_sub_lang_pc': 'none', 'cltfm_pc': 'OpenAIRE', 'dataset_title_kor': '', 'dataset_title_etc_main': 'Mpox Narrative on Instagram: A Labeled Multilingual Dataset of Instagram Posts on Mpox for Sentiment, Hate Speech, and Anxiety Analysis', 'dataset_title_etc_sub': '', 'dataset_expl_kor': '', 'dataset_expl_etc_main': '&lt;b&gt;Please cite the following paper when using this dataset:&lt;/b&gt; &lt;br&gt; N. Thakur, “Mpox narrative on Instagram: A labeled multilingual dataset of Instagram posts on mpox for sentiment, hate speech, and anxiety analysis,” arXiv [cs.LG], 2024, URL: https://arxiv.org/abs/2409.05292 &lt;br&gt; &lt;br&gt; &lt;b&gt;Abstract&lt;/b&gt; &lt;br&gt; The world is currently experiencing an outbreak of mpox, which has been declared a Public Health Emergency of International Concern by WHO. During recent virus outbreaks, social media platforms have played a crucial role in keeping the global population informed and updated regarding various aspects of the outbreaks. As a result, in the last few years, researchers from different disciplines have focused on the development of social media datasets focusing on different virus outbreaks. No prior work in this field has focused on the development of a dataset of Instagram posts about the mpox outbreak. The work presented in this paper (stated above) aims to address this research gap. It presents this &lt;b&gt;multilingual dataset of 60,127 Instagram posts&lt;/b&gt; about mpox, published between &lt;b&gt;July 23, 2022, and September 5, 2024.&lt;/b&gt; This dataset contains Instagram posts about mpox in &lt;b&gt;52 languages&lt;/b&gt;.   For each of these posts, the Post ID, Post Description, Date of publication, language, and translated version of the post (translation to English was performed using the Google Translate API) are presented as separate attributes in the dataset.  &lt;br&gt;&lt;br&gt; After developing this dataset, sentiment analysis, hate speech detection, and anxiety or stress detection were also performed. This process included classifying each post into  &lt;ul&gt;  &lt;li&gt;one of the fine-grain sentiment classes, i.e., &lt;b&gt;fear, surprise, joy, sadness, anger, disgust, or neutral&lt;/b&gt;&lt;/li&gt;  &lt;li&gt;&lt;b&gt;hate or not hate&lt;/b&gt;&lt;/li&gt;  &lt;li&gt;&lt;b&gt;anxiety/stress detected or no anxiety/stress detected&lt;/b&gt;&lt;/li&gt; &lt;/ul&gt; &lt;br&gt; These results are presented as &lt;b&gt;separate attributes&lt;/b&gt; in the dataset for the training and testing of machine learning algorithms for sentiment, hate speech, and anxiety or stress detection, as well as for other applications.  &lt;br&gt; &lt;br&gt; &lt;b&gt;The distinct languages in which Instagram posts are present in this dataset are &lt;/b&gt; English, Portuguese, Indonesian, Spanish, Korean, French, Hindi, Finnish, Turkish, Italian, German, Tamil, Urdu, Thai, Arabic, Persian, Tagalog, Dutch, Catalan, Bengali, Marathi, Malayalam, Swahili, Afrikaans, Panjabi, Gujarati, Somali, Lithuanian, Norwegian, Estonian, Swedish, Telugu, Russian, Danish, Slovak, Japanese, Kannada, Polish, Vietnamese, Hebrew, Romanian, Nepali, Czech, Modern Greek, Albanian, Croatian, Slovenian, Bulgarian, Ukrainian, Welsh, Hungarian, and Latvian &lt;br&gt; &lt;br&gt; &lt;b&gt;The following is a description of the attributes present in this dataset:&lt;/b&gt; &lt;ul&gt;  &lt;li&gt;&lt;b&gt;Post ID&lt;/b&gt;: Unique ID of each Instagram post&lt;/li&gt;  &lt;li&gt;&lt;b&gt;Post Description&lt;/b&gt;: Complete description of each post in the language in which it was originally published&lt;/li&gt;  &lt;li&gt;&lt;b&gt;Date&lt;/b&gt;: Date of publication in MM/DD/YYYY format&lt;/li&gt;  &lt;li&gt;&lt;b&gt;Language&lt;/b&gt;: Language of the post as detected using the Google Translate API &lt;/li&gt;  &lt;li&gt;&lt;b&gt;Translated Post Description&lt;/b&gt;: Translated version of the post description. All posts which were not in English were translated into English using the Google Translate API. No language translation was performed for English posts.&lt;/li&gt;  &lt;li&gt;&lt;b&gt;Sentiment&lt;/b&gt;: Results of sentiment analysis (using the preprocessed version of the translated Post Description) where each post was classified into one of the sentiment classes: fear, surprise, joy, sadness, anger, disgust, and neutral&lt;/li&gt;   &lt;li&gt;&lt;b&gt;Hate&lt;/b&gt;: Results of hate speech detection (using the preprocessed version of the translated Post Description) where each post was classified as hate or not hate&lt;/li&gt;  &lt;li&gt;&lt;b&gt;Anxiety or Stress&lt;/b&gt;: Results of anxiety or stress detection (using the preprocessed version of the translated Post Description) where each post was classified as stress/anxiety detected or no stress/anxiety detected. &lt;/li&gt; &lt;/ul&gt; &lt;br&gt; &lt;br&gt; All the Instagram posts that were collected during this data mining process to develop this dataset were publicly available on Instagram and did not require a user to log in to Instagram to view the same (at the time of writing this paper).;The dataset can be directly used for training and testing of machine learning algorithms for sentiment, hate speech, and anxiety or stress detection, as well as for other applications.', 'dataset_expl_etc_sub': 'The dataset can be directly used for training and testing of machine learning algorithms for sentiment, hate speech, and anxiety or stress detection, as well as for other applications.', 'dataset_kywd_kor': '', 'dataset_kywd_etc_main': 'text classification;data analysis;Social Sciences;Mathematical Sciences;epidemic;mpox;WHO;Engineering;dataset;syndromic surveillance;emotion analysis;virus outbreak;Computer and Information Science;public discourse;public health;artificial intelligence;neural networks;Google Translate;machine learning;classification;Medicine, Health and Life Sciences;sentiment analysis;Instagram;monkeypox;stress analysis;public perception;language translation;social networks;hate speech;social media;online behavior;text mining;unsupervised learning;supervised learning;NLP;online hate;social media mining;toxic content detection;pandemic studies;toxic language;health communication;information retrieval;natural language processing;multilingual dataset;anxiety detection;language detection;pandemic;health misinformation;pattern recognition;social media platforms;LGBTQ+ stigma;data mining;misinformation analysis;web mining;public attitudes;AI;mpox stigma;online misinformation;Other;data science;social contagion;user-generated content', 'dataset_kywd_etc_sub': 'data analysis', 'cltfm_kor': '', 'cltfm_etc': 'OpenAIRE', 'dataset_data_loc': '{coordinates:[0.0,0.0],type:point}', 'dataset_lndgpg': 'https://dx.doi.org/10.21227/7fvc-y093;https://dx.doi.org/10.5281/zenodo.13738598;https://dx.doi.org/10.6084/m9.figshare.27072247.v1;https://dx.doi.org/10.6084/m9.figshare.27072247;https://dx.doi.org/10.5281/zenodo.13738597;https://dx.doi.org/10.7910/dvn/tjvsy0', 'dataset_lndgpg_img': '', 'dataset_lndgpg_thum': '', 'dataset_doi': '', 'dataset_etc_attr': '', 'dataset_regist_dt': '2025-02-18 12:25:47', 'dataset_creat_dt': '2024-01-01', 'dataset_mod_dt': '0001-01-01 00:00:00', 'dataset_mnsb_pc': ['none'], 'file_frmt_pc': ['none'], 'pjt_prfrm_org_pc': ['none'], 'ministry_pc': ['none'], 'dataset_creator_kor': [], 'dataset_creator_etc_main': ['Thakur, Nirmalya'], 'dataset_creator_etc_sub': [], 'pjt_prfrm_org_kor': [], 'pjt_prfrm_org_etc': [], 'ministry_kor': [], 'ministry_etc': [], 'pjt_nm_kor': [], 'pjt_nm_etc': [], 'pjt_mngr_kor': [], 'pjt_mngr_etc': [], 'dataset_cntrbtr_kor': [], 'dataset_cntrbtr_etc': [], 'dataset_pblshr': [], 'dataset_pric': []}, {'svc_id': '9c723508590d42b85b0f9f773e794ba0', 'ctlg_type': '02', 'dataset_type': '02', 'ctlg_type_pc': 'dataset', 'dataset_type_pc': '해외', 'dataset_pub_dt_pc': '2024', 'dataset_access_type_pc': '공개', 'file_yn_pc': '랜딩페이지이동', 'dataset_cc_license_pc': 'CC-BY-4.0', 'dataset_main_lang_pc': 'English', 'dataset_sub_lang_pc': 'none', 'cltfm_pc': 'OpenAIRE', 'dataset_title_kor': '', 'dataset_title_etc_main': 'Sapsaree.fasta', 'dataset_title_etc_sub': '', 'dataset_expl_kor': '', 'dataset_expl_etc_main': '<b>Korean Sapsaree </b><b>Illumina 170K CanineHD BeadChip</b><b> Data</b><b><i>Dataset Overview:</i></b> This dataset contains genomic data from a group of Korean Sapsaree dogs. It specifically includes genetic information from 234 individual dogs, each genotyped using the Illumina 170K CanineHD BeadChip.<br><b><i>Files Included:</i></b><b>Sapsaree.fasta:</b> This file contains the genotypic data of the Korean Sapsaree dogs in FASTA format, a widely used text-based format for representing nucleotide sequences. Each entry corresponds to a single dog, with headers that provide identifying information followed by the sequence data.<br><b><i>Purpose of the Dataset:</i></b>The main purpose of releasing this dataset is to enhance the scientific understanding of Sapsaree dogs. By making these data available, we aim to support further research into canine genetics and breeding strategies that can lead to improvements in canine health and traits. Access to the data for reproducing results requires an application to, and permission from, the authors.', 'dataset_expl_etc_sub': '', 'dataset_kywd_kor': '', 'dataset_kywd_etc_main': '', 'dataset_kywd_etc_sub': '', 'cltfm_kor': '', 'cltfm_etc': 'OpenAIRE', 'dataset_data_loc': '{coordinates:[0.0,0.0],type:point}', 'dataset_lndgpg': 'https://dx.doi.org/10.6084/m9.figshare.25769994.v1', 'dataset_lndgpg_img': '', 'dataset_lndgpg_thum': '', 'dataset_doi': '', 'dataset_etc_attr': '', 'dataset_regist_dt': '2025-03-15 05:20:01', 'dataset_creat_dt': '2024-01-01', 'dataset_mod_dt': '0001-01-01 00:00:00', 'dataset_mnsb_pc': ['none'], 'file_frmt_pc': ['none'], 'pjt_prfrm_org_pc': ['none'], 'ministry_pc': ['none'], 'dataset_creator_kor': [], 'dataset_creator_etc_main': ['Haque, Md Azizul', 'Kim, Jong-Joo'], 'dataset_creator_etc_sub': [], 'pjt_prfrm_org_kor': [], 'pjt_prfrm_org_etc': [], 'ministry_kor': [], 'ministry_etc': [], 'pjt_nm_kor': [], 'pjt_nm_etc': [], 'pjt_mngr_kor': [], 'pjt_mngr_etc': [], 'dataset_cntrbtr_kor': [], 'dataset_cntrbtr_etc': [], 'dataset_pblshr': [], 'dataset_pric': []}, {'svc_id': '47362dcdad1390d223faaa7325e37ef9', 'ctlg_type': '02', 'dataset_type': '02', 'ctlg_type_pc': 'dataset', 'dataset_type_pc': '해외', 'dataset_pub_dt_pc': '2024', 'dataset_access_type_pc': '공개', 'file_yn_pc': '랜딩페이지이동', 'dataset_cc_license_pc': 'CC-BY-4.0', 'dataset_main_lang_pc': 'English', 'dataset_sub_lang_pc': 'none', 'cltfm_pc': 'OpenAIRE', 'dataset_title_kor': '', 'dataset_title_etc_main': '<b>Genomic Prediction and Genome-wide Association Studies in Korean Sapsaree Dogs</b>', 'dataset_title_etc_sub': '', 'dataset_expl_kor': '', 'dataset_expl_etc_main': '<b>Korean Sapsaree </b><b>Illumina 170K CanineHD BeadChip</b><b> Data</b><b><i>Dataset Overview:</i></b> This dataset contains genomic data from a group of Korean Sapsaree dogs. It specifically includes genetic information from 234 individual dogs, each genotyped using the Illumina 170K CanineHD BeadChip.<br><b><i>Files Included:</i></b><b>Sapsaree.fasta:</b> This file contains the genotypic data of the Korean Sapsaree dogs in FASTA format, a widely used text-based format for representing nucleotide sequences. Each entry corresponds to a single dog, with headers that provide identifying information followed by the sequence data.<br><b><i>Purpose of the Dataset:</i></b>The main purpose of releasing this dataset is to enhance the scientific understanding of Sapsaree dogs. By making these data available, we aim to support further research into canine genetics and breeding strategies that can lead to improvements in canine health and traits. Access to the data for reproducing results requires an application to, and permission from, the authors.', 'dataset_expl_etc_sub': '', 'dataset_kywd_kor': '', 'dataset_kywd_etc_main': '', 'dataset_kywd_etc_sub': '', 'cltfm_kor': '', 'cltfm_etc': 'OpenAIRE', 'dataset_data_loc': '{coordinates:[0.0,0.0],type:point}', 'dataset_lndgpg': 'https://dx.doi.org/10.6084/m9.figshare.25769994.v2;https://dx.doi.org/10.6084/m9.figshare.25769994', 'dataset_lndgpg_img': '', 'dataset_lndgpg_thum': '', 'dataset_doi': '', 'dataset_etc_attr': '', 'dataset_regist_dt': '2025-02-18 14:48:12', 'dataset_creat_dt': '2024-01-01', 'dataset_mod_dt': '0001-01-01 00:00:00', 'dataset_mnsb_pc': ['none'], 'file_frmt_pc': ['none'], 'pjt_prfrm_org_pc': ['none'], 'ministry_pc': ['none'], 'dataset_creator_kor': [], 'dataset_creator_etc_main': ['Haque, Md Azizul', 'Kim, Na-Kuang', 'Yeji, Ryu', 'Lee, Bugeun', 'Ha, Ji-Hong', 'Lee, Yun Mi', 'Il, Han-Kook', 'Joo, Kim Jong'], 'dataset_creator_etc_sub': [], 'pjt_prfrm_org_kor': [], 'pjt_prfrm_org_etc': [], 'ministry_kor': [], 'ministry_etc': [], 'pjt_nm_kor': [], 'pjt_nm_etc': [], 'pjt_mngr_kor': [], 'pjt_mngr_etc': [], 'dataset_cntrbtr_kor': [], 'dataset_cntrbtr_etc': [], 'dataset_pblshr': [], 'dataset_pric': []}]}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import os, requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# API_KEY = os.getenv(\"DATAON_SEARCH_API_KEY\")\n",
    "# assert API_KEY and API_KEY.strip(), \"환경변수(DATAON_API_KEY)가 비어있어요!\"\n",
    "\n",
    "# url = \"https://dataon.kisti.re.kr/rest/api/search/dataset/\"\n",
    "# params = {\"key\": API_KEY, \"query\": \"korean text\", \"from\": 0, \"size\": 5}\n",
    "# # key / CHAR / 필수 / API_KEY\n",
    "# # query / CHAR / 필수 / 검색키워드\n",
    "# # from / CHAR / 옵션 / 페이지시작위치\n",
    "# # size / CHAR / 옵션 / 페이지사이즈\n",
    "\n",
    "# print(\"🔎 호출 URL 미리보기:\", requests.Request('GET', url, params=params).prepare().url)\n",
    "# res = requests.get(url, params=params, timeout=20)\n",
    "# print(\"HTTP\", res.status_code)\n",
    "# data = res.json()\n",
    "# print(data)\n",
    "\n",
    "\n",
    "def Search_API_Call(query: str):\n",
    "    API_KEY = os.getenv(\"DATAON_SEARCH_API_KEY\")\n",
    "    assert API_KEY and API_KEY.strip(), \"환경변수(DATAON_API_KEY)가 비어있어요!\"\n",
    "\n",
    "    url = \"https://dataon.kisti.re.kr/rest/api/search/dataset/\"\n",
    "    params = {\"key\": API_KEY, \"query\": \"korean text\", \"from\": 0, \"size\": 5}\n",
    "    # key / CHAR / 필수 / API_KEY\n",
    "    # query / CHAR / 필수 / 검색키워드\n",
    "    # from / CHAR / 옵션 / 페이지시작위치\n",
    "    # size / CHAR / 옵션 / 페이지사이즈\n",
    "\n",
    "    # print(\"🔎 호출 URL 미리보기:\", requests.Request('GET', url, params=params).prepare().url)\n",
    "    res = requests.get(url, params=params, timeout=20)\n",
    "    print(\"HTTP\", res.status_code)\n",
    "    data = res.json()\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b6efddf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP 200\n",
      "response JSON:\n",
      "{\n",
      "  \"errorMessage\": \"(토큰발급용)MAC Address 확인 불가\",\n",
      "  \"errorCode\": \"E4006\",\n",
      "  \"statusMessage\": \"Bad Request\",\n",
      "  \"statusCode\": \"400\"\n",
      "}\n",
      "access token 키를 자동으로 찾지 못함. 위 JSON을 확인해줘.\n"
     ]
    }
   ],
   "source": [
    "# resp 는 이미 requests.get(...) 결과라고 가정\n",
    "import json\n",
    "import re\n",
    "\n",
    "print(\"HTTP\", resp.status_code)\n",
    "\n",
    "# 1) JSON 파싱 시도 — pretty print\n",
    "try:\n",
    "    data = resp.json()\n",
    "    print(\"response JSON:\")\n",
    "    print(json.dumps(data, ensure_ascii=False, indent=2))\n",
    "\n",
    "    # 2) 토큰 추출 시도(자주 쓰이는 키 목록 검사)\n",
    "    candidate_keys = [\"access_token\", \"accessToken\", \"token\", \"accessTokenInfo\", \"result\"]\n",
    "    token = None\n",
    "    for k in candidate_keys:\n",
    "        # 직접 키가 있는 경우\n",
    "        if isinstance(data, dict) and k in data:\n",
    "            # 직접 문자열이면 사용, dict이면 더 찾아봄\n",
    "            v = data[k]\n",
    "            if isinstance(v, str):\n",
    "                token = v; break\n",
    "            if isinstance(v, dict):\n",
    "                # 내부에 access_token 있을 수도 있음\n",
    "                for subk in (\"access_token\", \"accessToken\", \"token\"):\n",
    "                    if subk in v and isinstance(v[subk], str):\n",
    "                        token = v[subk]; break\n",
    "                if token: break\n",
    "\n",
    "    if token:\n",
    "        print(\"access token (found):\", token)\n",
    "    else:\n",
    "        print(\"access token 키를 자동으로 찾지 못함. 위 JSON을 확인해줘.\")\n",
    "except ValueError:\n",
    "    # JSON 아님 -> 텍스트 검색 시도\n",
    "    text = resp.text\n",
    "    print(\"response text (non-json):\")\n",
    "    print(text[:1000])  # 너무 길면 일부만 출력\n",
    "\n",
    "    # 간단한 토큰 패턴(예: 길고 랜덤한 문자열) 탐색(선택적)\n",
    "    m = re.search(r'([A-Za-z0-9\\-\\._]{20,200})', text)\n",
    "    if m:\n",
    "        print(\"heuristic token-like match:\", m.group(1))\n",
    "    else:\n",
    "        print(\"토큰 형태의 문자열을 찾지 못함. 전체 응답을 확인해봐.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f2197d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "print(type(now))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bd260149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6E-BD-E0-6B-BE-DE 20251007230040\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv, dotenv_values\n",
    "\n",
    "load_dotenv(override=True)\n",
    "MAC_ADDRESS = os.getenv('MAC_ADDRESS')\n",
    "print(MAC_ADDRESS, dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766af4d3",
   "metadata": {},
   "source": [
    "디버깅 중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65be49af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iv-param test -> 200 https://apigateway.kisti.re.kr/tokenrequest.do?client_id=e37c8354a854dad4e74fe1238b2921f8e47e34ddcaacbd3243d01caa93e874c8&accounts=4o7DiRqSx7BVacjy9RbhdrIV3%2FME%2F19wakmZOLfgBpWMYeu3HpiK%2BzoPKJCeJIDeqiq%2B2npi5pAVIQ0ZZnnUpw%3D%3D&iv=xmRmNXYcpODyH71uOwivlA%3D%3D\n",
      "{\"errorMessage\":\"(토큰발급용)MAC Address 확인 불가\",\"errorCode\":\"E4006\",\"statusMessage\":\"Bad Request\",\"statusCode\":\"400\"}\n"
     ]
    }
   ],
   "source": [
    "b64 = base64.b64encode(ciphertext).decode('ascii')        # ciphertext만\n",
    "iv_b64 = base64.b64encode(iv).decode('ascii')\n",
    "params = {\"client_id\": CLIENT_ID, \"accounts\": b64, \"iv\": iv_b64}\n",
    "r = requests.get(\"https://apigateway.kisti.re.kr/tokenrequest.do\", params=params, timeout=15)\n",
    "print(\"iv-param test ->\", r.status_code, r.url)\n",
    "print(r.text[:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4f473",
   "metadata": {},
   "source": [
    "# 아래가 지금 쓸 예정인 것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b86a3c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1C-57-DC-50-BB-31\n",
      "20251008202421\n",
      "len(key_bytes)= 32\n",
      "URL sent: https://apigateway.kisti.re.kr/tokenrequest.do?accounts=%255BD%2523%25DC%2524Xv%25DE%25A4%25A8%25B3%25E0%2592%259D%25E0h%259B%2540%2584%253D%255B%25B3pR%25D4%2590%2520A%25FD.%25F3%25FD%2510%25FE%2580%25A2%25B4J%25C6%258F%2591%2505%2512%2595%2540%2512%253A%25E3%25E8%25AB%2500mvy%2521%25AD%2504%25A3%250E%25C1%250A4%25CB3&client_id=e37c8354a854dad4e74fe1238b2921f8e47e34ddcaacbd3243d01caa93e874c8\n",
      "HTTP 200\n",
      "{\"errorMessage\":\"(토큰발급용)MAC Address 확인 불가\",\"errorCode\":\"E4006\",\"statusMessage\":\"Bad Request\",\"statusCode\":\"400\"}\n"
     ]
    }
   ],
   "source": [
    "import os, requests, json, base64\n",
    "from datetime import datetime\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Util.Padding import pad, unpad\n",
    "from dotenv import load_dotenv\n",
    "from urllib import parse\n",
    "\n",
    "load_dotenv(override=True)\n",
    "CLIENT_ID = os.getenv(\"SCIENCEON_CLIENT_ID\")\n",
    "API_KEY = os.getenv(\"SCIENCEON_API_KEY\")  # 네가 발급받은 32자리 인증키(문자열)\n",
    "MAC_RAW = os.getenv(\"MAC_ADDRESS\")\n",
    "\n",
    "# 1) 정규화 (필수)\n",
    "mac = (MAC_RAW or \"\").strip().upper().replace(\":\", \"-\")\n",
    "if not mac:\n",
    "    raise SystemExit(\"MAC_ADDRESS가 비어있음\")\n",
    "print(mac)\n",
    "\n",
    "# 2) datetime\n",
    "dt = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "print(dt)\n",
    "\n",
    "# 3) accounts json (compact)\n",
    "accounts_json = json.dumps({\"mac_address\": mac, \"datetime\": dt}, separators=(\",\", \":\")).encode()\n",
    "# print(\"accounts_json:\", accounts_json.decode('utf-8'))\n",
    "# print(mac, dt)\n",
    "\n",
    "# 4) key 준비 (확인: key_bytes 길이 반드시 16/24/32)\n",
    "key_bytes = bytes(API_KEY, 'utf-8')\n",
    "print(\"len(key_bytes)=\", len(key_bytes))\n",
    "\n",
    "if len(key_bytes) not in (16,24,32):\n",
    "    raise SystemExit(\"API_KEY 길이 문제: AES 키는 16/24/32 바이트여야 함\")\n",
    "\n",
    "# 5) 암호화 (ECB)\n",
    "cipher = AES.new(key_bytes, AES.MODE_ECB)\n",
    "ciphertext = cipher.encrypt(pad(accounts_json, AES.block_size))\n",
    "\n",
    "result = parse.quote(ciphertext)\n",
    "params = {\"accounts\": result, \"client_id\": CLIENT_ID}\n",
    "\n",
    "\n",
    "# 8) 요청 (requests가 자동 URL 인코딩 함)\n",
    "url = \"https://apigateway.kisti.re.kr/tokenrequest.do\"\n",
    "r = requests.get(url, params=params, timeout=15)\n",
    "print(\"URL sent:\", r.url)\n",
    "print(\"HTTP\", r.status_code)\n",
    "print(r.text[:800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9ac02628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'7cd1621a60d946f4997329ecdfce1df3'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key_bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcfd3703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b64 preview: W0Qj3CRYdt6kqLPgkp3gaJtAhD1bs3BS1JAgQf0u8/0Q/oCitErGj5EFEpVAEjrjUDxnvlQYt1CXHjnm\n",
      "endswith '=' : True\n"
     ]
    }
   ],
   "source": [
    "import base64, urllib.parse\n",
    "\n",
    "# b64_std 는 네가 전송한 b64 문자열 (패딩 유지)\n",
    "print(\"b64 preview:\", b64_std[:80])\n",
    "print(\"endswith '=' :\", b64_std.endswith(\"=\"))\n",
    "\n",
    "# 서버가 받을 실제 텍스트(예: requests가 전송하는 URL 이후에 서버가 디코딩할 값)를\n",
    "# 시뮬레이션하려면 URL 인코딩 후 다시 디코딩해보면 된다:\n",
    "encoded = urllib.parse.quote_plus(b64_std)   # requests가 URL에 넣는 형태\n",
    "decoded = urllib.parse.unquote_plus(encoded)\n",
    "assert decoded == b64_std\n",
    "# base64 디코딩으로 payload가 돌아오는지 확인\n",
    "payload = base64.b64decode(decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa67882d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'mac_address': '1C-57-DC-50-BB-31', 'datetime': '20251007234828'}\n"
     ]
    }
   ],
   "source": [
    "t = {\"mac_address\": mac, \"datetime\": dt}\n",
    "tj = json.dumps(t)\n",
    "type(tj)\n",
    "tj\n",
    "\n",
    "# 2) 파일로 저장 (추천: json.dump, 사람이 읽기 좋게 indent 추가)\n",
    "with open(\"data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(t, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# 3) 파일에서 읽기\n",
    "with open(\"data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "print(type(data))  # <class 'dict'>\n",
    "print(data)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a492d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) accounts JSON 생성\n",
    "accounts_json = make_accounts_json(MAC, DATETIME)\n",
    "print(\"accounts_json:\", accounts_json)\n",
    "\n",
    "# 2) 키/IV 준비\n",
    "key = derive_key_from_passphrase(PASSPHRASE)       # 32 bytes (AES-256)\n",
    "iv = b\"\\x00\" * 16                                 # 예시 IV (문서에 IV가 있으면 그걸 사용)\n",
    "\n",
    "# 3) AES-256-CBC 암호화 (PKCS7 패딩 적용)\n",
    "ciphertext = aes256_cbc_encrypt(accounts_json.encode(\"utf-8\"), key, iv)\n",
    "cipher = AES.new(key_bytes, AES.MODE_EBC)\n",
    "    return cipher.encrypt(pad(plaintext_bytes, AES.block_size))\n",
    "\n",
    "# 4) 암호문을 URL-safe base64로 인코딩 (padding 제거 선택 가능)\n",
    "b64 = base64.urlsafe_b64encode(ciphertext).decode(\"ascii\").rstrip(\"=\")\n",
    "\n",
    "# 5) URI 인코딩 (문서이행성 때문에 추가)\n",
    "accounts_param = urllib.parse.quote_plus(b64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c3d32cc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data must be aligned to block boundary in ECB mode",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m text = \u001b[33m\"\u001b[39m\u001b[33mm05G3Thk9yD7+TLsb2VyS5SCg5JLVDB6/pggbVlkROEw1DkX1MdlevFM2LZzmuAeWrMKxzrpTg2Cuc2tpbILc8bBKKdXxUJhK09uM3vHCls=\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m decrypted_text = unpad(\u001b[43mcipher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecrypt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m, AES.block_size)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Dropbox/kisti_data_ai/kisti_recommender/venv/lib/python3.13/site-packages/Crypto/Cipher/_mode_ecb.py:196\u001b[39m, in \u001b[36mEcbMode.decrypt\u001b[39m\u001b[34m(self, ciphertext, output)\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    195\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result == \u001b[32m3\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mData must be aligned to block boundary in ECB mode\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    197\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mError \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m while decrypting in ECB mode\u001b[39m\u001b[33m\"\u001b[39m % result)\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mValueError\u001b[39m: Data must be aligned to block boundary in ECB mode"
     ]
    }
   ],
   "source": [
    "text = \"m05G3Thk9yD7+TLsb2VyS5SCg5JLVDB6/pggbVlkROEw1DkX1MdlevFM2LZzmuAeWrMKxzrpTg2Cuc2tpbILc8bBKKdXxUJhK09uM3vHCls=\"\n",
    "\n",
    "decrypted_text = unpad(cipher.decrypt(text.encode('utf-8')), AES.block_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c026bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Crypto.Cipher import AES\n",
    "from Crypto.Util.Padding import unpad\n",
    "import base64\n",
    "\n",
    "text = \"m05G3Thk9yD7+TLsb2VyS5SCg5JLVDB6/pggbVlkROEw1DkX1MdlevFM2LZzmuAeWrMKxzrpTg2Cuc2tpbILc8bBKKdXxUJhK09uM3vHCls=\"\n",
    "ciphertext = base64.b64decode(text)   # ← 중요: base64 디코딩\n",
    "\n",
    "print(\"len(ciphertext) =\", len(ciphertext), \"mod 16 =\", len(ciphertext) % 16)\n",
    "\n",
    "key = b\"your16bytekey!!\"  # 16/24/32 바이트여야 함\n",
    "cipher = AES.new(key, AES.MODE_ECB)\n",
    "\n",
    "plaintext = unpad(cipher.decrypt(ciphertext), AES.block_size)\n",
    "print(plaintext.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5833347f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mac = (MAC_ADDRESS or \"\").strip().strip('\"').strip(\"'\").upper().replace(\":\", \"-\")\n",
    "if not mac:\n",
    "    raise SystemExit(\"MAC_ADDRESS가 비어있음\")\n",
    "print(mac)\n",
    "\n",
    "# datetime 생성\n",
    "dt = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "print(dt)\n",
    "\n",
    "# JSON 페이로드 생성\n",
    "payload = {\n",
    "    \"mac_address\": mac,\n",
    "    \"datetime\": dt\n",
    "}\n",
    "plain_json = json.dumps(payload, separators=(',', ':'))\n",
    "\n",
    "# AES 암호화 → Base64\n",
    "aes = AESTestClass(plain_txt=plain_json, key=API_KEY)\n",
    "b64_cipher = aes.encrypt()\n",
    "\n",
    "# 인코딩 + 토큰 요청\n",
    "endpoint = \"https://apigateway.kisti.re.kr/tokenrequest.do\"\n",
    "params = {\n",
    "    \"accounts\": b64_cipher,\n",
    "    \"client_id\": CLIENT_ID\n",
    "}\n",
    "\n",
    "print(\"🔎 호출 URL 미리보기:\", requests.Request('GET', endpoint, params=params).prepare().url)\n",
    "response = requests.get(endpoint, params=params, timeout=10)\n",
    "response.raise_for_status()\n",
    "print(\"HTTP\", response.status_code)\n",
    "\n",
    "# 결과 출력\n",
    "print(response.text)\n",
    "\n",
    "data = response.json()\n",
    "type(data)\n",
    "token = data['access_token']\n",
    "token\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
