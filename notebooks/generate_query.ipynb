{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49aa0c94",
   "metadata": {},
   "source": [
    "# 검색어 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d2cc8",
   "metadata": {},
   "source": [
    "## 결과물 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8cd90a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import Field, BaseModel\n",
    "\n",
    "class QueryResult(BaseModel):\n",
    "    query: Annotated[\n",
    "        list[str],\n",
    "        Field(\n",
    "            ..., \n",
    "            max_length=5, \n",
    "            min_length=5,\n",
    "            description=\"가장 적절한 검색어들의 리스트\", \n",
    "        )\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe8c96d8",
   "metadata": {},
   "source": [
    "## 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45ab5f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "query_length = 5\n",
    "# Prompt\n",
    "query_template_1 = f'''\n",
    "Generate search queries to find the most semantically relevant papers and datasets based on the given title, description and keywords.\n",
    "\n",
    "[Search Engine Constraints]\n",
    "- The search is exact-match based.\n",
    "- Keep queries short and cohesive.\n",
    "- Each query should consist of 2–3 words, preferably a combination of proper nouns or technical topics.\n",
    "\n",
    "[Generation Procedure]\n",
    "1. Identify Core Keywords: Summarize the main objects, methodology, domain, and application context of the research topic in one sentence.\n",
    "2. Generate Candidates: Tentatively generate 8–10 query candidates, each with 2–3 words.\n",
    "3. Apply Filtering Rules:\n",
    "    - Remove generic, overly broad, or ambiguous expressions (e.g., “AI model”, “data analysis”).\n",
    "    - Keep a balanced mix — 12 method-centered, 12 domain-centered, and 1–2 application-scenario-centered queries.\n",
    "    - Exclude entries consisting only of abbreviations, but allow widely used ones (e.g., “BERT” is allowed, “ML” alone is not).\n",
    "    - Do not use hyphens, special characters, or quotation marks.\n",
    "4. Final Selection: Retain only the top {query_length}.\n",
    "\n",
    "[Prohibitions]\n",
    "- Single-word queries are not allowed.\n",
    "- Queries longer than 4 words are not allowed.\n",
    "- Do not leave only stopword combinations (e.g., “for research”).\n",
    "- Do not violate the JSON schema.\n",
    "\n",
    "'''\n",
    "\n",
    "query_template_2 = '''\n",
    "[Input]\n",
    "- Research Topic: {title}\n",
    "- Research Description: {description}\n",
    "- Keywords: {keyword}\n",
    "\n",
    "[Output]\n",
    "Output in the following JSON format:\n",
    "\n",
    "{{\n",
    "\"query\": []\n",
    "}}\n",
    "'''\n",
    "\n",
    "query_prompt = PromptTemplate.from_template(query_template_1 + query_template_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c943a5",
   "metadata": {},
   "source": [
    "## 예시 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "357805ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# title/description/keyword\n",
    "with open(\"../data/input_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "try:\n",
    "    title, description, keyword = input_data['dataset_title_etc_main'], input_data['dataset_expl_etc_main'], input_data['dataset_kywd_etc_main']\n",
    "\n",
    "except:\n",
    "    items = input_data[\"MetaData\"][\"recordList\"][\"record\"][\"item\"]\n",
    "    title = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"Title\")\n",
    "    description = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"Abstract\")\n",
    "    keyword = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"Keyword\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a4bf76",
   "metadata": {},
   "source": [
    "## 작동 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b3b287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ross Sea core', 'Antarctic climate', 'gravity core', 'marine sediments', 'sedimentation study']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "prompt = query_prompt.invoke(\n",
    "    {\n",
    "        'title': title, \n",
    "        'description': description,\n",
    "        'keyword': keyword\n",
    "    }\n",
    ")\n",
    "\n",
    "# sLLM\n",
    "sllm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "structured_sllm = sllm.with_structured_output(QueryResult)\n",
    "res = structured_sllm.invoke(prompt)\n",
    "\n",
    "query = res.query\n",
    "\n",
    "# with open('../data/queries.txt', 'w', encoding='utf-8') as sf:\n",
    "#     f.write('\\n'.join(query))\n",
    "\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4457a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
