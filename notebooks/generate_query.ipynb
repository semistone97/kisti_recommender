{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49aa0c94",
   "metadata": {},
   "source": [
    "## 검색어 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd90a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import Field, BaseModel\n",
    "\n",
    "class QueryResult(BaseModel):\n",
    "    query: Annotated[\n",
    "        list[str],\n",
    "        Field(\n",
    "            ..., \n",
    "            max_length=5, \n",
    "            min_length=3,\n",
    "            description=\"가장 적절한 검색어들의 리스트, 길이 최소 3개/최대 5개\", \n",
    "        )\n",
    "    ]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "45ab5f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 프롬프트\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "query_template = '''\n",
    "주어진 제목과 설명을 바탕으로, 의미적으로 가장 관련성이 높은 논문과 데이터셋을 찾기 위한 검색어를 생성하세요.\n",
    "\n",
    "[검색 엔진 제약]\n",
    "검색은 정확 일치 기반입니다. 쿼리는 짧고 응집력 있게 만드세요.\n",
    "각 쿼리는 2~3단어, 고유명사나 기술 토픽의 조합을 선호합니다.\n",
    "\n",
    "[생성 절차]\n",
    "1. 주제 핵심어 파악: 연구 주제의 주요 객체, 방법론, 도메인, 응용 맥락을 한 문장으로 요약\n",
    "2. 후보 생성: 2~3단어 쿼리 후보를 8~10개 잠정 생성\n",
    "3. 필터링 규칙 적용:\n",
    "  - 일반어, 지나치게 포괄적이거나 모호한 표현 제거(ex: “AI model”, “data analysis”)\n",
    "  - 12개는 방법론 중심, 12개는 도메인 중심, 1~2개는 응용 시나리오 중심으로 균형 있게 남김\n",
    "  - 약어만 있는 경우는 배제하되, 널리 쓰이는 고유 약어는 유지(ex: “BERT” 가능, “ML” 단독 불가)\n",
    "  - 하이픈, 특수문자, 따옴표는 사용하지 않음\n",
    "4. 최종 선택: 상위 3~5개만 남김\n",
    "\n",
    "[금지]\n",
    "- 1단어 쿼리 금지\n",
    "- 4단어 이상 금지\n",
    "- 불용어만 남는 조합 금지(ex: “for research”)\n",
    "- JSON 스키마 위반 금지\n",
    "\n",
    "[Input]\n",
    "- 연구 주제: {title}\n",
    "- 연구 설명: {description}\n",
    "- 키워드: {keyword}\n",
    "\n",
    "[Output]\n",
    "다음 형식의 JSON을 출력하세요:\n",
    "{{\n",
    "  \"query\": [],\n",
    "}}\n",
    "'''\n",
    "\n",
    "query_prompt = PromptTemplate.from_template(query_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61b3b287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Antarctic gravity core', 'Ross Sea sediments', 'climate change Antarctica', 'marine sedimentation', 'gravity core analysis']\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "with open(\"../data/input_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "title, description, keyword = input_data['dataset_title_etc_main'], input_data['dataset_expl_etc_main'], input_data['dataset_kywd_etc_main']\n",
    "\n",
    "prompt = query_prompt.invoke(\n",
    "    {\n",
    "        'title': title, \n",
    "        'description': description,\n",
    "        'keyword': keyword\n",
    "    }\n",
    ")\n",
    "\n",
    "# sLLM\n",
    "sllm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "structured_sllm = sllm.with_structured_output(QueryResult)\n",
    "res = structured_sllm.invoke(prompt)\n",
    "\n",
    "print(res.query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560415ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
