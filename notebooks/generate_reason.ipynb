{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56bf2391",
   "metadata": {},
   "source": [
    "# 추천사유 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bace422f",
   "metadata": {},
   "source": [
    "## 결과물 형태"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9fb6ea6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schema\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import Field, BaseModel\n",
    "\n",
    "class IDRelevance(BaseModel):\n",
    "    relevant_id: Annotated[\n",
    "        list[str],\n",
    "        Field(\n",
    "            ..., \n",
    "            description=(\n",
    "                \"데이터의 ID 목록\"\n",
    "            ), \n",
    "        )\n",
    "    ]\n",
    "    reason: Annotated[\n",
    "        list[str],\n",
    "        Field(\n",
    "            ..., \n",
    "            description=\"각 ID가 선정된 이유를 설명하는 문자열 목록. relevant_id와 인덱스가 일치해야 합니다.\",\n",
    "        )\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531fb6ee",
   "metadata": {},
   "source": [
    "## 프롬프트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "039bc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompt\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "reason_template = '''\n",
    "You are a data scientist. Your task is to explain clearly why each listed paper or dataset\n",
    "was selected for recommendation, so that users can easily understand the reasoning.\n",
    "\n",
    "[Writing Guidelines]\n",
    "1) You must provide exactly one explanation for each ID. Do not give overall summaries.\n",
    "2) Each reason must explicitly describe the connection between the research topic and the data item.\n",
    "3) Each reason should include at least two of the following elements:\n",
    "   \n",
    "Keyword or topical similarity\n",
    "Alignment in methodology or model\n",
    "Match in domain or application context\n",
    "4) Use an objective, descriptive tone. Avoid exaggeration or subjective evaluation.\n",
    "5) Each reason should be 1–2 sentences long, about 60 words or fewer.\n",
    "6) The number of items in \"relevant_id\" and \"reason\" must be identical,\n",
    "   and the index i of each list must correspond to the same item.\n",
    "7) Do not output any text other than JSON, and use only the keys \"relevant_id\" and \"reason\".\n",
    "\n",
    "[Self-check]\n",
    "Before finalizing your output, verify that the lengths of \"relevant_id\" and \"reason\" are equal.\n",
    "If they differ, adjust the list of reasons to match the number of IDs.\n",
    "If a reason sounds too generic, directly reference at least one supporting term\n",
    "from the input topic, or from that item’s title or keywords.\n",
    "\n",
    "[Input]\n",
    "Research Topic: {title}\n",
    "Research Description: {description}\n",
    "Keywords: {keyword}\n",
    "\n",
    "[Data]\n",
    "Data list:\n",
    "{data}\n",
    "\n",
    "[Output(JSON)]\n",
    "{{\n",
    "  \"relevant_id\": [],\n",
    "  \"reason\": []\n",
    "}}\n",
    "'''\n",
    "\n",
    "\n",
    "reason_prompt = PromptTemplate.from_template(reason_template)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94391c3",
   "metadata": {},
   "source": [
    "## 예시 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c148bfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title, description, keyword\n",
    "import json\n",
    "\n",
    "with open(\"../data/input_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "try:\n",
    "    title = input_data['dataset_title_etc_main']\n",
    "    description = input_data['dataset_expl_etc_main']\n",
    "    keyword = input_data['dataset_expl_etc_main']\n",
    "    input_id = input_data['svc_id']\n",
    "\n",
    "except:\n",
    "    items = input_data[\"MetaData\"][\"recordList\"][\"record\"][\"item\"]\n",
    "    title = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"Title\")\n",
    "    description = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"Abstract\")\n",
    "    keyword = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"Keyword\")\n",
    "    input_id = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"CN\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b25fac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import pandas as pd\n",
    "\n",
    "df_article = pd.read_csv('../data/search_results_article.csv', encoding='UTF-8', low_memory=False)\n",
    "df_data = pd.read_csv('../data/search_results_dataset.csv', encoding='UTF-8', low_memory=False)\n",
    "\n",
    "cleaned_df_data = (\n",
    "    df_data[\n",
    "        ['svc_id', 'dataset_title_etc_main', 'dataset_expl_etc_main','dataset_pub_dt_pc', 'dataset_kywd_etc_main', 'dataset_creator_etc_main', 'dataset_lndgpg', 'query']\n",
    "    ]\n",
    "    .rename(\n",
    "        columns={\n",
    "            'svc_id': 'ID',\n",
    "            'dataset_title_etc_main': 'title',\n",
    "            'dataset_expl_etc_main': 'description',\n",
    "            'dataset_pub_dt_pc': 'pubyear',\n",
    "            'dataset_kywd_etc_main': 'keyword',\n",
    "            'dataset_creator_etc_main': 'author',\n",
    "            'dataset_lndgpg': 'URL',\n",
    "        }\n",
    "    )\n",
    ")\n",
    "cleaned_df_data['category'] = 'dataset'\n",
    "\n",
    "cleaned_df_arti = (\n",
    "    df_article[\n",
    "        ['CN', 'Title', 'Abstract', 'Pubyear', 'Keyword', 'Author', 'ContentURL', 'query']\n",
    "    ]\n",
    "    .rename(\n",
    "        columns={\n",
    "            'CN': 'ID',\n",
    "            'Title': 'title',\n",
    "            'Abstract': 'description',\n",
    "            'Pubyear': 'pubyear',\n",
    "            'Keyword': 'keyword',\n",
    "            'Author': 'author',\n",
    "            'ContentURL': 'URL'\n",
    "        }\n",
    "    )\n",
    ")\n",
    "cleaned_df_arti['category'] = 'article'\n",
    "\n",
    "df = pd.concat([cleaned_df_arti, cleaned_df_data], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ff3099",
   "metadata": {},
   "outputs": [],
   "source": [
    "# relevance_data\n",
    "relevance_df = pd.read_csv('../data/relevance_results.csv', encoding='UTF-8', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee55eee",
   "metadata": {},
   "source": [
    "## 작동 방식"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06c5070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "relevance",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "reason",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "682a82c7-7e87-4672-8c4e-f44db515a376",
       "rows": [
        [
         "0",
         "d023e479d6a3e09f0d7988cf38a4436b",
         "99.72029",
         "The gravity core from the same region (O.Granite Harbor) and year (2014/2015) aligns closely with RS15-GC76, providing additional data for climate change observations."
        ],
        [
         "1",
         "ff96e62579ae3046d133440562968c39",
         "99.45315",
         "This dataset also comes from O.Granite Harbor and shares the same year and focus on Antarctic climate change, enhancing the understanding of sedimentation patterns."
        ],
        [
         "2",
         "21f628ecb675030dedda1149f466adae",
         "99.09062",
         "This gravity core is from the Ross Sea and shares the same year of collection, contributing to the broader context of Antarctic climate change research."
        ],
        [
         "3",
         "e83e64b3b4ea6a9982da08310ea27b1b",
         "98.75883",
         "Similar to RS15-GC76, this dataset includes a gravity core from the Ross Sea, with a focus on climate change, allowing for a comprehensive study of sedimentation in the region."
        ],
        [
         "4",
         "83d26621eaf49e20d987f3d7d4005122",
         "98.718956",
         "This dataset features a gravity core from the Ross Sea, similar to RS15-GC76, and focuses on Antarctic climate change, making it relevant for comparative analysis."
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>relevance</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d023e479d6a3e09f0d7988cf38a4436b</td>\n",
       "      <td>99.720290</td>\n",
       "      <td>The gravity core from the same region (O.Grani...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff96e62579ae3046d133440562968c39</td>\n",
       "      <td>99.453150</td>\n",
       "      <td>This dataset also comes from O.Granite Harbor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21f628ecb675030dedda1149f466adae</td>\n",
       "      <td>99.090620</td>\n",
       "      <td>This gravity core is from the Ross Sea and sha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e83e64b3b4ea6a9982da08310ea27b1b</td>\n",
       "      <td>98.758830</td>\n",
       "      <td>Similar to RS15-GC76, this dataset includes a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83d26621eaf49e20d987f3d7d4005122</td>\n",
       "      <td>98.718956</td>\n",
       "      <td>This dataset features a gravity core from the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  relevance  \\\n",
       "0  d023e479d6a3e09f0d7988cf38a4436b  99.720290   \n",
       "1  ff96e62579ae3046d133440562968c39  99.453150   \n",
       "2  21f628ecb675030dedda1149f466adae  99.090620   \n",
       "3  e83e64b3b4ea6a9982da08310ea27b1b  98.758830   \n",
       "4  83d26621eaf49e20d987f3d7d4005122  98.718956   \n",
       "\n",
       "                                              reason  \n",
       "0  The gravity core from the same region (O.Grani...  \n",
       "1  This dataset also comes from O.Granite Harbor ...  \n",
       "2  This gravity core is from the Ross Sea and sha...  \n",
       "3  Similar to RS15-GC76, this dataset includes a ...  \n",
       "4  This dataset features a gravity core from the ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Node\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "relevant_ids = relevance_df['ID'].tolist()\n",
    "filtered_df = df[df['ID'].isin(relevant_ids)]\n",
    "\n",
    "prompt = reason_prompt.invoke(\n",
    "    {\n",
    "        'title': title, \n",
    "        'description': description,\n",
    "        'keyword': keyword,\n",
    "        'data': filtered_df[['ID', 'title', 'description', 'keyword']].to_dict(orient=\"records\"),\n",
    "    }\n",
    ")\n",
    "\n",
    "sllm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "structured_sllm = sllm.with_structured_output(IDRelevance)\n",
    "res = structured_sllm.invoke(prompt)\n",
    "    \n",
    "tmp = pd.DataFrame({\n",
    "    'ID': res.relevant_id,\n",
    "    'reason': res.reason\n",
    "})\n",
    "\n",
    "relevance_df = pd.merge(\n",
    "    relevance_df[['ID', 'relevance']],\n",
    "    tmp,\n",
    "    on='ID',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# relevance_df.to_csv('../data/relevance_results.csv', index=False, encoding='utf-8')\n",
    "\n",
    "display(relevance_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
