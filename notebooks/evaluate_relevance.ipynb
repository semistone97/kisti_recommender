{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0954a3c0",
   "metadata": {},
   "source": [
    "# 연관성 점수 부여"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db9418",
   "metadata": {},
   "source": [
    "## 예시 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0bfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# title, description, keyword\n",
    "import json\n",
    "\n",
    "with open(\"../data/input_data.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    input_data = json.load(f)\n",
    "\n",
    "try:\n",
    "    title = input_data['dataset_title_etc_main']\n",
    "    description = input_data['dataset_expl_etc_main']\n",
    "    keyword = input_data['dataset_expl_etc_main']\n",
    "    input_id = input_data['svc_id']\n",
    "\n",
    "except:\n",
    "    items = input_data[\"MetaData\"][\"recordList\"][\"record\"][\"item\"]\n",
    "    title = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"Title\")\n",
    "    description = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"Abstract\")\n",
    "    keyword = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"Keyword\")\n",
    "    input_id = next(i[\"#text\"] for i in items if i[\"@metaCode\"] == \"CN\")\n",
    "    \n",
    "state = {'title': title, 'description': description, 'keyword': keyword, 'input_id': input_id}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f01dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "import pandas as pd\n",
    "\n",
    "df_article = pd.read_csv('../data/search_results_article.csv', encoding='UTF-8', low_memory=False)\n",
    "df_data = pd.read_csv('../data/search_results_dataset.csv', encoding='UTF-8', low_memory=False)\n",
    "\n",
    "cleaned_df_data = (\n",
    "    df_data[\n",
    "        ['svc_id', 'dataset_title_etc_main', 'dataset_expl_etc_main','dataset_pub_dt_pc', 'dataset_kywd_etc_main', 'dataset_creator_etc_main', 'dataset_lndgpg', 'query']\n",
    "    ]\n",
    "    .rename(\n",
    "        columns={\n",
    "            'svc_id': 'ID',\n",
    "            'dataset_title_etc_main': 'title',\n",
    "            'dataset_expl_etc_main': 'description',\n",
    "            'dataset_pub_dt_pc': 'pubyear',\n",
    "            'dataset_kywd_etc_main': 'keyword',\n",
    "            'dataset_creator_etc_main': 'author',\n",
    "            'dataset_lndgpg': 'URL',\n",
    "        }\n",
    "    )\n",
    ")\n",
    "cleaned_df_data['category'] = 'dataset'\n",
    "\n",
    "cleaned_df_arti = (\n",
    "    df_article[\n",
    "        ['CN', 'Title', 'Abstract', 'Pubyear', 'Keyword', 'Author', 'ContentURL', 'query']\n",
    "    ]\n",
    "    .rename(\n",
    "        columns={\n",
    "            'CN': 'ID',\n",
    "            'Title': 'title',\n",
    "            'Abstract': 'description',\n",
    "            'Pubyear': 'pubyear',\n",
    "            'Keyword': 'keyword',\n",
    "            'Author': 'author',\n",
    "            'ContentURL': 'URL'\n",
    "        }\n",
    "    )\n",
    ")\n",
    "cleaned_df_arti['category'] = 'article'\n",
    "\n",
    "df = pd.concat([cleaned_df_arti, cleaned_df_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa78618e",
   "metadata": {},
   "source": [
    "## 임베딩을 통한 연관성 점수 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f8cb92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[embedding_title]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[embedding_description]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[embedding_keyword]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.47s/it]\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "ID",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "relevance",
         "rawType": "float32",
         "type": "float"
        }
       ],
       "ref": "a1246cdf-b223-4fb6-aa8d-44e69c1119bd",
       "rows": [
        [
         "0",
         "d023e479d6a3e09f0d7988cf38a4436b",
         "92.56636"
        ],
        [
         "1",
         "ff96e62579ae3046d133440562968c39",
         "92.31045"
        ],
        [
         "2",
         "21f628ecb675030dedda1149f466adae",
         "91.94792"
        ],
        [
         "3",
         "e83e64b3b4ea6a9982da08310ea27b1b",
         "91.60432"
        ],
        [
         "4",
         "83d26621eaf49e20d987f3d7d4005122",
         "91.57433"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>relevance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d023e479d6a3e09f0d7988cf38a4436b</td>\n",
       "      <td>92.566360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ff96e62579ae3046d133440562968c39</td>\n",
       "      <td>92.310448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21f628ecb675030dedda1149f466adae</td>\n",
       "      <td>91.947922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e83e64b3b4ea6a9982da08310ea27b1b</td>\n",
       "      <td>91.604317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83d26621eaf49e20d987f3d7d4005122</td>\n",
       "      <td>91.574333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 ID  relevance\n",
       "0  d023e479d6a3e09f0d7988cf38a4436b  92.566360\n",
       "1  ff96e62579ae3046d133440562968c39  92.310448\n",
       "2  21f628ecb675030dedda1149f466adae  91.947922\n",
       "3  e83e64b3b4ea6a9982da08310ea27b1b  91.604317\n",
       "4  83d26621eaf49e20d987f3d7d4005122  91.574333"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "targets = ['title', 'description', 'keyword']\n",
    "\n",
    "MAX_LENGTH = 2000\n",
    "\n",
    "dfs = {}\n",
    "\n",
    "for target in targets:\n",
    "    print(f'\\n[embedding_{target}]')\n",
    "    \n",
    "    df[target] = df[target].fillna('')\n",
    "    df[target] = df[target].str.slice(0, MAX_LENGTH)\n",
    "\n",
    "    texts = df[target].tolist()\n",
    "\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "    docs = [Document(page_content=text, metadata={\"ID\": row.ID}) \n",
    "            for text, row in zip(texts, df.itertuples())]\n",
    "\n",
    "    batch_size = 500\n",
    "    stores = []\n",
    "    for i in tqdm(range(0, len(docs), batch_size)):\n",
    "        batch = docs[i:i+batch_size]\n",
    "        store = FAISS.from_documents(batch, embeddings)\n",
    "        stores.append(store)\n",
    "\n",
    "    vectorstore = stores[0]\n",
    "    for s in stores[1:]:\n",
    "        vectorstore.merge_from(s)\n",
    "\n",
    "    query = state[target]\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "    results_with_score = vectorstore.similarity_search_with_score_by_vector(query_embedding, k=20)\n",
    "    \n",
    "    dfs[f'df_{target}'] = pd.DataFrame([\n",
    "        {\n",
    "            \"ID\": r.metadata.get(\"ID\"),\n",
    "            \"relevance\": score,\n",
    "            \"target\": target\n",
    "        }\n",
    "        for r, score in results_with_score\n",
    "    ])\n",
    "    \n",
    "merged_df = dfs['df_title'].merge(\n",
    "    dfs['df_description'][[\"ID\", \"relevance\"]], \n",
    "    on=\"ID\",\n",
    "    how=\"outer\",\n",
    "    suffixes=(\"_title\", \"_desc\")\n",
    ").merge(\n",
    "    dfs['df_keyword'][[\"ID\", \"relevance\"]].rename(columns={\"relevance\": \"relevance_key\"}), \n",
    "    on=\"ID\",\n",
    "    how=\"outer\"\n",
    ")\n",
    "\n",
    "merged_df = merged_df.fillna(2.0)\n",
    "\n",
    "merged_df = merged_df.drop_duplicates(subset='ID')\n",
    "\n",
    "merged_df = merged_df[merged_df['ID'] != state['input_id']]\n",
    "\n",
    "# 2. 가중치 합산\n",
    "a, b, c = 10, 3, 1\n",
    "merged_df[\"relevance_raw\"] = (\n",
    "    merged_df[\"relevance_title\"] * a + \n",
    "    merged_df[\"relevance_desc\"] * b + \n",
    "    merged_df[\"relevance_key\"] * c\n",
    ") / (a + b + c)\n",
    "\n",
    "merged_df[\"relevance\"] = 100 * (1 - merged_df[\"relevance_raw\"] / 2)\n",
    "\n",
    "result_df = (merged_df[[\"ID\", \"relevance\"]]\n",
    "            .sort_values(\"relevance\", ascending=False)\n",
    "            .reset_index(drop=True)).head(5)\n",
    "\n",
    "result_df.to_csv('../data/relevance_results.csv', index=False, encoding='utf-8')\n",
    "\n",
    "display(result_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
