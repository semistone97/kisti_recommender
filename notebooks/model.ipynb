{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21868cd",
   "metadata": {},
   "source": [
    "# 모델 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "be3873f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6caef9",
   "metadata": {},
   "source": [
    "## Global State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "79c8e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "import pandas as pd\n",
    "from dataclasses import field\n",
    "\n",
    "\n",
    "class State(MessagesState):\n",
    "    \n",
    "    # 입력된 데이터\n",
    "    input_id: str = ''  \n",
    "    input_category: str = ''\n",
    "    \n",
    "    # 메타데이터 검색을 통해 확인한 제목과 설명\n",
    "    title: str = ''   \n",
    "    description: str = ''\n",
    "    keyword: str = ''\n",
    "    \n",
    "    # LLM이 생성한 검색어 리스트\n",
    "    query : list[str] = []\n",
    "    \n",
    "    # 검색어를 통해 검색한 전체 데이터\n",
    "    search_df: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "\n",
    "    # 연관성 검색을 통해 확인한 topK 데이터\n",
    "    relevance_df: pd.DataFrame = field(default_factory=pd.DataFrame)\n",
    "    \n",
    "    # 결과\n",
    "    result_df: pd.DataFrame = field(default_factory=pd.DataFrame)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9363ef43",
   "metadata": {},
   "source": [
    "## 논문 - API 호출용 토큰 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "bf99e4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, base64, requests\n",
    "from Crypto.Cipher import AES\n",
    "from datetime import datetime\n",
    "\n",
    "class AESTestClass:\n",
    "    def __init__(self, plain_txt, key):\n",
    "        # iv, block_size 값은 고정\n",
    "        self.iv = 'jvHJ1EFA0IXBrxxz'\n",
    "        self.block_size = 16\n",
    "        self.plain_txt = plain_txt\n",
    "        self.key = key\n",
    "\n",
    "    def pad(self):\n",
    "        # PKCS#7 패딩\n",
    "        number_of_bytes_to_pad = self.block_size - len(self.plain_txt) % self.block_size\n",
    "        ascii_str = chr(number_of_bytes_to_pad)\n",
    "        padding_str = number_of_bytes_to_pad * ascii_str\n",
    "        return self.plain_txt + padding_str\n",
    "\n",
    "    def encrypt(self):\n",
    "        cipher = AES.new(self.key.encode('utf-8'), AES.MODE_CBC, self.iv.encode('utf-8'))\n",
    "        padded_txt = self.pad()\n",
    "        encrypted_bytes = cipher.encrypt(padded_txt.encode('utf-8'))\n",
    "        # URL-safe Base64\n",
    "        encrypted_str = base64.urlsafe_b64encode(encrypted_bytes).decode('utf-8')\n",
    "        return encrypted_str\n",
    "    \n",
    "def call_access_token(MAC_ADDRESS, API_KEY, CLIENT_ID):\n",
    "    # 맥주소\n",
    "    mac = (MAC_ADDRESS or \"\").strip().strip('\"').strip(\"'\").upper().replace(\":\", \"-\")\n",
    "    if not mac:\n",
    "        raise SystemExit(\"MAC_ADDRESS가 비어있음\")\n",
    "\n",
    "    # datetime 생성\n",
    "    dt = datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "\n",
    "    # JSON 페이로드 생성\n",
    "    payload = {\n",
    "        \"mac_address\": mac,\n",
    "        \"datetime\": dt\n",
    "    }\n",
    "    plain_json = json.dumps(payload, separators=(',', ':'))\n",
    "\n",
    "    # AES 암호화 → Base64\n",
    "    aes = AESTestClass(plain_txt=plain_json, key=API_KEY)\n",
    "    b64_cipher = aes.encrypt()\n",
    "\n",
    "    # 인코딩 + 토큰 요청\n",
    "    endpoint = \"https://apigateway.kisti.re.kr/tokenrequest.do\"\n",
    "    params = {\n",
    "        \"accounts\": b64_cipher,\n",
    "        \"client_id\": CLIENT_ID\n",
    "    }\n",
    "\n",
    "    response = requests.get(endpoint, params=params, timeout=10)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    data = response.json()\n",
    "    token = data['access_token'] \n",
    "    return token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c640022",
   "metadata": {},
   "source": [
    "## 논문 - 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "bd644979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def xml_to_df(xml):\n",
    "    # XML 파싱\n",
    "    root = ET.fromstring(xml)\n",
    "\n",
    "    # recordList 찾기\n",
    "    record_list_element = root.find('recordList')\n",
    "\n",
    "    # 데이터를 담을 리스트\n",
    "    records = []\n",
    "\n",
    "    if record_list_element is not None:\n",
    "        # 각 record에 대해 반복\n",
    "        for record_element in record_list_element.findall('record'):\n",
    "            record_data = {}\n",
    "            # 각 item에 대해 반복\n",
    "            for item_element in record_element.findall('item'):\n",
    "                meta_code = item_element.get('metaCode')\n",
    "                # CDATA 섹션의 텍스트 추출\n",
    "                value = item_element.text.strip() if item_element.text else ''\n",
    "                record_data[meta_code] = value\n",
    "            records.append(record_data)\n",
    "\n",
    "    df = pd.DataFrame(records)\n",
    "    return df\n",
    "\n",
    "def transform_query(input_query):\n",
    "\n",
    "    query = {\n",
    "        \"BI\": input_query,  # 전체\n",
    "        # \"TI\": None,  # 논문명\n",
    "        # \"AU\": None,  # 저자\n",
    "        # \"AB\": None,  # 초록\n",
    "        # \"KW\": None,  # 키워드\n",
    "        # \"PB\": None,  # 출판사(발행기관)\n",
    "        # \"SN\": None,  # ISSN\n",
    "        # \"BN\": None,  # ISBN\n",
    "        # \"PY\": None,  # 발행년도\n",
    "        # \"CN\": None,  # 문헌번호\n",
    "        # \"DI\": None   # DOI\n",
    "    }\n",
    "\n",
    "    json_query = json.dumps(query, separators=(',', ':')) \n",
    "\n",
    "    return json_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06dbc843",
   "metadata": {},
   "source": [
    "## 논문 - 제목, 초록 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "d6e7dd73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, xmltodict\n",
    "\n",
    "def ARTI_browse(state: State):\n",
    "    \n",
    "    CLIENT_ID = os.getenv(\"SCIENCEON_CLIENT_ID\")\n",
    "    ARTI_KEY = os.getenv(\"SCIENCEON_API_KEY\")\n",
    "    MAC_ADDRESS = os.getenv(\"MAC_ADDRESS\")\n",
    "\n",
    "    access_token = call_access_token(MAC_ADDRESS, ARTI_KEY, CLIENT_ID)\n",
    "\n",
    "    url = \"https://apigateway.kisti.re.kr/openapicall.do\"\n",
    "    params = {\n",
    "        \"client_id\": CLIENT_ID,\n",
    "        \"token\": access_token,\n",
    "        \"version\": 1.0,\n",
    "        \"action\": \"browse\",\n",
    "        \"target\": \"ARTI\",\n",
    "        \"cn\": state['input_id'],\n",
    "        \"include\": \"\",\n",
    "        \"exclude\": None,\n",
    "    }\n",
    "    \n",
    "    res = requests.get(url, params=params, timeout=20)\n",
    "    xml = res.text\n",
    "    dict_data = xmltodict.parse(xml)\n",
    "    with open(\"../data/input_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dict_data, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    df = xml_to_df(xml)\n",
    "    \n",
    "    title, description, keyword = df['Title'].iloc[0], df['Abstract'].iloc[0], df['Keyword'].iloc[0]\n",
    "    \n",
    "    print('\\n[title]\\n', title)\n",
    "    print('\\n[description]\\n', description)\n",
    "    print('\\n[keyword]\\n', keyword)    \n",
    "\n",
    "    return {'title': title, 'description': description, 'keyword': keyword}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62813e19",
   "metadata": {},
   "source": [
    "## 데이터셋 - 제목, 설명 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "f909f616",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests, json\n",
    "\n",
    "def DATA_browse(state: State):\n",
    "\n",
    "    API_KEY = os.getenv(\"DATAON_META_API_KEY\")\n",
    "    assert API_KEY and API_KEY.strip(), \"환경변수(DATAON_META_API_KEY)가 비어있어요!\"\n",
    "\n",
    "    url = \"https://dataon.kisti.re.kr/rest/api/search/dataset/\" + state[\"input_id\"]\n",
    "    params = {\"key\": API_KEY}\n",
    "\n",
    "    res = requests.get(url, params=params, timeout=20)\n",
    "    data = res.json()\n",
    "\n",
    "    # json 저장\n",
    "    with open(\"../data/input_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data['records'], f, ensure_ascii=False, indent=4)\n",
    "\n",
    "    title, description, keyword = data['records']['dataset_title_etc_main'], data['records']['dataset_expl_etc_main'], data['records']['dataset_kywd_etc_main']\n",
    "    print('\\n[title]\\n', title)\n",
    "    print('\\n[description]\\n', description)\n",
    "    print('\\n[keyword]\\n', keyword)\n",
    "\n",
    "    return {'title':title, 'description' : description, 'keyword': keyword} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fb6461",
   "metadata": {},
   "source": [
    "## 검색어 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "3cf05987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from typing_extensions import Annotated\n",
    "from pydantic import Field, BaseModel\n",
    "\n",
    "# Schema\n",
    "class QueryResult(BaseModel):\n",
    "    query: Annotated[\n",
    "        list[str],\n",
    "        Field(\n",
    "            ..., \n",
    "            max_length=5, \n",
    "            min_length=3,\n",
    "            description=\"가장 적절한 검색어들의 리스트, 길이 최소 3개/최대 5개\", \n",
    "        )\n",
    "    ]\n",
    "    \n",
    "# Prompt\n",
    "query_template = '''\n",
    "주어진 제목과 설명, 키워드를 바탕으로, 가장 연관성이 높은 논문과 데이터셋을 검색하려 합니다.\n",
    "\n",
    "가장 의미적으로 관련성이 높은 논문과 데이터셋을 검색할 수 있을 쿼리를 만들어 주세요.\n",
    "\n",
    "[조건]\n",
    "1. 쿼리는 2~3단어로 구성되어야 합니다.\n",
    "2. 검색 방식은 쿼리와 정확히 일치하는 내용이 있는 논문이나 데이터를 반환하는 형식입니다.\n",
    "\n",
    "[Input]\n",
    "연구 주제: {title}\n",
    "연구 설명: {description}\n",
    "키워드: {keyword}\n",
    "\n",
    "[Output]\n",
    "가장 적절한 3~5개의 쿼리를 JSON으로 출력해주세요.\n",
    "'''\n",
    "\n",
    "query_prompt = PromptTemplate.from_template(query_template)\n",
    "\n",
    "# Node\n",
    "def generate_query(state: State):\n",
    "\n",
    "    prompt = query_prompt.invoke(\n",
    "        {\n",
    "            'title': state['title'], \n",
    "            'description': state['description'],\n",
    "            'keyword': state['keyword'],\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # sLLM\n",
    "    sllm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "    structured_sllm = sllm.with_structured_output(QueryResult)\n",
    "    res = structured_sllm.invoke(prompt)\n",
    "    query = res.query\n",
    "    print('\\n[query]\\n', query)\n",
    "\n",
    "    return {'query': query}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69681e0b",
   "metadata": {},
   "source": [
    "## 논문 - 쿼리에 따른 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "4d2d5687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "\n",
    "def ARTI_search(state: State):\n",
    "    \n",
    "    CLIENT_ID = os.getenv(\"SCIENCEON_CLIENT_ID\")\n",
    "    ARTI_KEY = os.getenv(\"SCIENCEON_API_KEY\")\n",
    "    MAC_ADDRESS = os.getenv(\"MAC_ADDRESS\")\n",
    "\n",
    "    access_token = call_access_token(MAC_ADDRESS, ARTI_KEY, CLIENT_ID)\n",
    "\n",
    "    url = \"https://apigateway.kisti.re.kr/openapicall.do\"\n",
    "    df = pd.DataFrame()\n",
    "    \n",
    "    for query in state['query']:\n",
    "        params = {\n",
    "            \"client_id\": CLIENT_ID,\n",
    "            \"token\": access_token,\n",
    "            \"version\": 1.0,\n",
    "            \"action\": \"search\",\n",
    "            \"target\": \"ARTI\",\n",
    "            \"searchQuery\": transform_query(query),\n",
    "            'curPage': 1, # 현재페이지 번호\n",
    "            'rowCount': 20, # 디스플레이 건수(기본값 10, 최대값 100)\n",
    "        }\n",
    "\n",
    "        res = requests.get(url, params=params, timeout=20)\n",
    "        xml = res.text\n",
    "        tmp = xml_to_df(xml)\n",
    "        tmp[\"query\"] = query\n",
    "        df = pd.concat([df, tmp], ignore_index=True)\n",
    "        \n",
    "    df = df.drop_duplicates(subset='CN')\n",
    "    df.to_csv('../data/search_results_article.csv', index=False, encoding='utf-8')\n",
    "    print('\\n[total article length]\\n', len(df))\n",
    "\n",
    "    cleaned_df = (\n",
    "        df[\n",
    "            ['CN', 'Title', 'Abstract', 'Pubyear', 'Keyword', 'Author', 'ContentURL', 'query']\n",
    "        ]\n",
    "        .rename(\n",
    "            columns={\n",
    "                'CN': 'ID',\n",
    "                'Title': 'title',\n",
    "                'Abstract': 'description',\n",
    "                'Pubyear': 'pubyear',\n",
    "                'Keyword': 'keyword',\n",
    "                'Author': 'author',\n",
    "                'ContentURL': 'URL'\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cleaned_df['category'] = 'article'\n",
    "\n",
    "    search_df = state.get('search_df')\n",
    "    \n",
    "    if search_df is not None and not search_df.empty:\n",
    "        return {'search_df': pd.concat([search_df, cleaned_df], ignore_index=True)}\n",
    "    else:\n",
    "        return {'search_df': cleaned_df}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61e60a4",
   "metadata": {},
   "source": [
    "## 데이터셋 - 쿼리에 따른 검색"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "821cafd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "import pandas as pd\n",
    "\n",
    "def DATA_search(state: State):\n",
    "    \n",
    "    API_KEY = os.getenv(\"DATAON_SEARCH_API_KEY\")\n",
    "    assert API_KEY and API_KEY.strip(), \"환경변수(DATAON_API_KEY)가 비어있어요!\"\n",
    "\n",
    "    url = \"https://dataon.kisti.re.kr/rest/api/search/dataset/\"\n",
    "    df = pd.DataFrame()\n",
    "    for query in state['query']:\n",
    "        params = {\"key\": API_KEY, \"query\": query, \"from\": 0, \"size\": 20}\n",
    "        # key / CHAR / 필수 / API_KEY\n",
    "        # query / CHAR / 필수 / 검색키워드\n",
    "        # from / CHAR / 옵션 / 페이지시작위치\n",
    "        # size / CHAR / 옵션 / 페이지사이즈\n",
    "\n",
    "        res = requests.get(url, params=params, timeout=20)\n",
    "        data = res.json()\n",
    "        \n",
    "        if \"records\" in data:\n",
    "            tmp = pd.DataFrame(data[\"records\"])\n",
    "            tmp[\"query\"] = query\n",
    "            df = pd.concat([df, tmp], ignore_index=True)\n",
    "\n",
    "    df = df.drop_duplicates(subset='svc_id')\n",
    "    df.to_csv('../data/search_results_dataset.csv', index=False, encoding='utf-8')\n",
    "    print('\\n[total dataset length]\\n', len(df))\n",
    "    \n",
    "    cleaned_df = (\n",
    "        df[\n",
    "            ['svc_id', 'dataset_title_etc_main', 'dataset_expl_etc_main','dataset_pub_dt_pc', 'dataset_kywd_etc_main', 'dataset_creator_etc_main', 'dataset_lndgpg', 'query']\n",
    "        ]\n",
    "        .rename(\n",
    "            columns={\n",
    "                'svc_id': 'ID',\n",
    "                'dataset_title_etc_main': 'title',\n",
    "                'dataset_expl_etc_main': 'description',\n",
    "                'dataset_pub_dt_pc': 'pubyear',\n",
    "                'dataset_kywd_etc_main': 'keyword',\n",
    "                'dataset_creator_etc_main': 'author',\n",
    "                'dataset_lndgpg': 'URL',\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "\n",
    "    cleaned_df['category'] = 'dataset'\n",
    "    \n",
    "    search_df = state.get('search_df')\n",
    "    \n",
    "    if search_df is not None and not search_df.empty:\n",
    "        return {'search_df': pd.concat([search_df, cleaned_df], ignore_index=True)}\n",
    "    else:\n",
    "        return {'search_df': cleaned_df}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e3140a",
   "metadata": {},
   "source": [
    "## 연관성 점수 부여"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "2de73930",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_relevance(state: State):\n",
    "    \n",
    "    df = state['search_df']\n",
    "\n",
    "    targets = ['title', 'description', 'keyword']\n",
    "\n",
    "    MAX_LENGTH = 2000\n",
    "\n",
    "    dfs = {}\n",
    "\n",
    "    for target in targets:\n",
    "        print(f'\\n[embedding_{target}]')\n",
    "        \n",
    "        df[target] = df[target].fillna('')\n",
    "        df[target] = df[target].str.slice(0, MAX_LENGTH)\n",
    "\n",
    "        texts = df[target].tolist()\n",
    "\n",
    "        embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "\n",
    "        docs = [Document(page_content=text, metadata={\"ID\": row.ID}) \n",
    "                for text, row in zip(texts, df.itertuples())]\n",
    "\n",
    "        batch_size = 500\n",
    "        stores = []\n",
    "        for i in tqdm(range(0, len(docs), batch_size)):\n",
    "            batch = docs[i:i+batch_size]\n",
    "            store = FAISS.from_documents(batch, embeddings)\n",
    "            stores.append(store)\n",
    "\n",
    "        vectorstore = stores[0]\n",
    "        for s in stores[1:]:\n",
    "            vectorstore.merge_from(s)\n",
    "\n",
    "        query = state[target]\n",
    "        query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "        results_with_score = vectorstore.similarity_search_with_score_by_vector(query_embedding, k=20)\n",
    "        \n",
    "        dfs[f'df_{target}'] = pd.DataFrame([\n",
    "            {\n",
    "                \"ID\": r.metadata.get(\"ID\"),\n",
    "                \"relevance\": score,\n",
    "                \"target\": target\n",
    "            }\n",
    "            for r, score in results_with_score\n",
    "        ])\n",
    "        \n",
    "    merged_df = dfs['df_title'].merge(\n",
    "        dfs['df_description'][[\"ID\", \"relevance\"]], \n",
    "        on=\"ID\",\n",
    "        how=\"outer\",\n",
    "        suffixes=(\"_title\", \"_desc\")\n",
    "    ).merge(\n",
    "        dfs['df_keyword'][[\"ID\", \"relevance\"]].rename(columns={\"relevance\": \"relevance_key\"}), \n",
    "        on=\"ID\",\n",
    "        how=\"outer\"\n",
    "    )\n",
    "\n",
    "    merged_df = merged_df.fillna(2.0)\n",
    "\n",
    "    merged_df = merged_df.drop_duplicates(subset='ID')\n",
    "\n",
    "    merged_df = merged_df[merged_df['ID'] != state['input_id']]\n",
    "\n",
    "    # 2. 가중치 합산\n",
    "    a, b, c = 10, 3, 1\n",
    "    merged_df[\"relevance_raw\"] = (\n",
    "        merged_df[\"relevance_title\"] * a + \n",
    "        merged_df[\"relevance_desc\"] * b + \n",
    "        merged_df[\"relevance_key\"] * c\n",
    "    ) / (a + b + c)\n",
    "\n",
    "    merged_df[\"relevance\"] = 100 * (1 - merged_df[\"relevance_raw\"] / 2)\n",
    "\n",
    "    result_df = (merged_df[[\"ID\", \"relevance\"]]\n",
    "                .sort_values(\"relevance\", ascending=False)\n",
    "                .reset_index(drop=True)).head(5)\n",
    "\n",
    "    return {'relevance_df': result_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c40e4b3c",
   "metadata": {},
   "source": [
    "## 추천사유 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "380e754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing_extensions import Annotated\n",
    "from pydantic import Field, BaseModel\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Schema\n",
    "class IDRelevance(BaseModel):\n",
    "    relevant_id: Annotated[\n",
    "        list[str],\n",
    "        Field(\n",
    "            ..., \n",
    "            description=(\n",
    "                \"데이터의 ID 목록\"\n",
    "            ), \n",
    "        )\n",
    "    ]\n",
    "    reason: Annotated[\n",
    "        list[str],\n",
    "        Field(\n",
    "            ..., \n",
    "            description=\"각 ID가 선정된 이유를 설명하는 문자열 목록. relevant_id와 인덱스가 일치해야 합니다.\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "# Prompt\n",
    "reason_template = '''\n",
    "당신은 데이터 과학자입니다. 아래는 연구 데이터 목록입니다.\n",
    "\n",
    "각 데이터 혹은 논문 항목은 다음 컬럼을 가지고 있습니다:\n",
    "- ID: 각 데이터의 고유키\n",
    "- 제목\n",
    "- 설명\n",
    "- 키워드\n",
    "\n",
    "[목표]\n",
    "모든 항목에 대해 해당 항목의 선정 사유를 작성해 주세요.\n",
    "\n",
    "**중요: relevant_id와 reason의 개수는 반드시 동일해야 합니다.**\n",
    "\n",
    "[Input]\n",
    "연구 주제: {title}\n",
    "연구 설명: {description}\n",
    "키워드: {keyword}\n",
    "\n",
    "[Data]\n",
    "데이터 목록:\n",
    "{data}\n",
    "\n",
    "[Output]\n",
    "다음 형식의 JSON을 출력하세요. relevant_id와 reason의 길이가 정확히 일치해야 합니다:\n",
    "\n",
    "{{\n",
    "  \"relevant_id\": [\"ID1\", \"ID2\", \"ID3\"],\n",
    "  \"reason\": [\"이유1\", \"이유2\", \"이유3\"]\n",
    "}}\n",
    "'''\n",
    "\n",
    "reason_prompt = PromptTemplate.from_template(reason_template)\n",
    "\n",
    "# Node\n",
    "def generate_reason(state: State):\n",
    "    print('\\ngenerating reasons...\\n')\n",
    "    df, title, description, keyword = state['search_df'], state['title'], state['description'], state['keyword']\n",
    "    \n",
    "    relevant_ids = state['relevance_df']['ID'].tolist()\n",
    "    filtered_df = df[df['ID'].isin(relevant_ids)]\n",
    "\n",
    "    prompt = reason_prompt.invoke(\n",
    "        {\n",
    "            'title': title, \n",
    "            'description': description,\n",
    "            'keyword': keyword,\n",
    "            'data': filtered_df[['ID', 'title', 'description', 'keyword']].to_dict(orient=\"records\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    sllm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "\n",
    "    structured_sllm = sllm.with_structured_output(IDRelevance)\n",
    "    res = structured_sllm.invoke(prompt)\n",
    "        \n",
    "    tmp = pd.DataFrame({\n",
    "        'ID': res.relevant_id,\n",
    "        'reason': res.reason\n",
    "    })\n",
    "    \n",
    "    relevance_df = pd.merge(\n",
    "        state['relevance_df'],\n",
    "        tmp,\n",
    "        on='ID',\n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return {'relevance_df': relevance_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0161095",
   "metadata": {},
   "source": [
    "## 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "7da84af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_results(state: State):\n",
    "    \n",
    "    merged_df = pd.merge(\n",
    "        state['relevance_df'],\n",
    "        state['search_df'][['ID','category', 'title', 'description', 'URL']],\n",
    "        on='ID',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    result_df = merged_df[['category', 'title', 'description', 'relevance', 'reason', 'URL']]\n",
    "    result_df = result_df.rename(columns={\n",
    "        'category': '구분',\n",
    "        'title': '제목',\n",
    "        'description': '설명',\n",
    "        'relevance': '점수',\n",
    "        'reason': '추천 사유',\n",
    "    })\n",
    "\n",
    "    return {'result_df': result_df}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1b6939",
   "metadata": {},
   "source": [
    "# 그래프 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "03cf2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_router(state):\n",
    "\n",
    "    if state['input_category'] == 'article':\n",
    "        return 'article'\n",
    "    \n",
    "    if state['input_category'] == 'dataset':\n",
    "        return 'dataset'\n",
    "\n",
    "    return 'END'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "0d8926b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "def build_graph():\n",
    "    builder = StateGraph(State)\n",
    "    \n",
    "    builder.add_sequence([generate_query, ARTI_search, DATA_search, evaluate_relevance, generate_reason, summarize_results]) \n",
    "    builder.add_node('DATA_browse', DATA_browse)\n",
    "    builder.add_node('ARTI_browse', ARTI_browse)\n",
    "    \n",
    "    builder.add_conditional_edges(\n",
    "        START,\n",
    "        input_router,\n",
    "        {\n",
    "            'article': 'ARTI_browse',\n",
    "            'dataset': 'DATA_browse'\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    builder.add_edge('ARTI_browse', 'generate_query')\n",
    "    builder.add_edge('DATA_browse', 'generate_query')\n",
    "    \n",
    "    builder.add_edge('summarize_results', END)\n",
    "    \n",
    "    return builder.compile()\n",
    "\n",
    "graph = build_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "89ecf795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[input_id]\n",
      " JAKO200411922932805\n",
      "\n",
      "[title]\n",
      " 한국인의 3차원 무릎관절 구축 및 형상 측정\n",
      "\n",
      "[description]\n",
      " It is necessary to have a model that describes the feature of the knee Joint with a sufficient accuracy. Koreans, however, do not have their own knee joint model to be used in the total knee replacement arthroplasty. They have to use European or American models which do not match Koreans. Three-dimensional visualization techniques are found to be useful in a wide range of medical applications. Three-dimensional imaging studies such as CT(computed tomography) and MRI(magnetic resonance image) provide the primary source of patient-specific data. Three-dimensional knee joint models were constructed by image processing of the CT data of 10 subjects. Using the constructed model, the dimensions of Korean knee joint were measured. And this study proposed a three-dimensional model and data, which can be helpful to develop Korean knee implants and to analyze knee joint movements.\n",
      "\n",
      "[keyword]\n",
      " 단층촬영사진 . 한국인 무릎 관절 모델 . 인공 관절 치환술\n",
      "\n",
      "[query]\n",
      " ['한국인 무릎관절', '3차원 무릎 모델', 'CT 무릎관절', '인공관절 치환술', '무릎관절 형상 측정']\n",
      "\n",
      "[total article length]\n",
      " 91\n",
      "\n",
      "[total dataset length]\n",
      " 35\n",
      "\n",
      "[embedding_title]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[embedding_description]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[embedding_keyword]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "generating reasons...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "구분",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "제목",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "설명",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "점수",
         "rawType": "float32",
         "type": "float"
        },
        {
         "name": "추천 사유",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "URL",
         "rawType": "object",
         "type": "string"
        }
       ],
       "ref": "4a5a91a9-c6c5-4d5a-8b41-10d83b7b59e9",
       "rows": [
        [
         "0",
         "article",
         "한국인의 3차원 무릎 관절 모델 구축 및 형상 측정",
         "It is necessary to have a model that describes the feature of the knee joint with a sufficient accuracy. Koreans, however, do not have their own knee joint model used in the total knee replacement arthroplasty. They have to use European and American models but they do not match to Korean's knee joint components. Past days many doctors actually measured the knee joint shape using calipers while operating patients or the size of 2D image-like as computed tomography (CT) and magnetic resonance image. Recently, three-dimensional visualization techniques are found to be useful in a wide range of medical applications. Three-dimensional imaging studies such as CT and MRI provide the primary source of patient-specific data. In this study, three dimensional knee joint models were constructed by image processing of CT data for 15 persons. Using the constructed model, the size of knee joint of Korean was measured. Finally this study proposed the method and standard of measurement by using 3D knee joint model. The proposed 3D model and data and method of measurement can be helpful to develop Korean knee implant and analysis of knee joint movement.",
         "92.39738",
         "이 연구는 한국인의 무릎관절 모델을 구축하고 형상을 측정하여, 한국인에 적합한 인공관절 설계에 기여할 수 있는 중요한 데이터입니다.",
         "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0010027329"
        ],
        [
         "1",
         "dataset",
         "무릎 인공관절 형상 설계에 활용할 수 있는 한국인 남녀 무릎 관절의 형상 및 치수 데이터의 제작",
         "1. 관절면 영상 생성  한국인의 무릎 인공관절 형상 설계에 활용할 수 있는 남녀 무릎 관절의 형상 및 치수 자료를 구축하기 위해서 2003년, 2004년에 구축된 디지털 코리언 인체 데이터 남성 시신 44표본, 여성 시신 58표본을 사용하였다. Mimics(Ver.13) 소프트웨어를 사용하여 인체의 넙다리뼈, 무릎뼈, 정강뼈의 3차원 영상을 생성한 뒤에 보행 시의 뼈의 위치에 맞추기 위해 각각의 개별 뼈 모델을 보행 축에 맞도록 재정렬 하였다. 넙다리뼈, 무릅뼈, 정강뼈 측정의 기준 스케일로 사용할 40 mm 구를 무릎 관절의 옆쪽에 생성하고 여러 방향에서의 관절면 영상을 캡춰하여 관절면 영상을 생성하였다. 보다 상세한 내용은 KISTI에서 운영하는 디지털 코리언 홈페이지(http://dk.kisti.re.kr)를 참조하기 바란다.  2. 절단면 영상 생성  또한 위의 3차원 개별뼈 모델에 실제 무릎인공관절 수술에서 사용되는 방법으로 관절면을 절단하여 가상으로 수술된 상태의 3차원 뼈 모델을 제작하고 절단면의 치수 측정을 위해 기준 스케일로 사용할 40 mm 구를 무릎 관절의 옆쪽에 생성하고 가상 수술이 완료된 뼈 절단면의 2차원 절단면 영상 파일을 생성하였다.  3. 관절면, 절단면의 치수 측정  무릎 관절의 형상을 표현하는 관절면과 가상 수술된 절단면의 주요 부분의 치수를 측정하기 위하여 CAD 프로그램인 Cadian 소프트웨어를 사용하여 넙다리뼈, 무릎뼈, 정강뼈의 관절면과 절단면의 주요한 측정 부위를 선정하고 그 치수를 측정하였다. 보다 상세한 내용은 KISTI에서 운영하는 디지털 코리언 홈페이지(http://dk.kisti.re.kr)를 참조하기 바란다.",
         "62.567184",
         "이 연구는 한국인 남녀의 무릎 관절 형상 및 치수 데이터를 제작하여, 인공관절 형상 설계에 필요한 기초 자료를 제공합니다.",
         "https://dk.kisti.re.kr/?q=node/9"
        ],
        [
         "2",
         "article",
         "자기공명영상 기반 3차원 유한요소모델링을 통한 무릎관절의 파손평가",
         "본 연구에서는 먼저 완전 신전상태의 병변이 없는 26세 남자의 자기공명영상이미지를 기반으로 대퇴골, 경골, 관절연골, 반월상 연골의 정밀한 3차원 재구축을 실시하였다. 재구축된 무릎모델에 인대와 건을 생리학적으로 적합한 위치에 부착시켜 3차원 유한요소모델을 완성시켰다. 뼈, 관절연골, 반월상 연골은 균질성, 등방성 선형탄성거동을 보이는 것으로 고려하였으며, 인대와 건은 트러스 요소와 선형, 비선형 스프링 요소를 사용하여 모델링하였다. 제작된 무릎관절의 유한요소모델을 ABAQUS를 사용하여 비선형 접촉해석을 수행하였다. 수치해석결과로서 조직의 손상과 환자의 통증을 추정하기 위한 중요매개변수로 간주될 수 있는 관절연골과 반월상연골의 접촉압력과 von Mises 응력분포를 계산하였으며, 관절연골과 반월상 연골의 접촉압력과 von Mises 응력분포를 분석하여 무릎관절에 대한 파손평가를 실시하였다.",
         "58.63395",
         "이 연구는 자기공명영상 기반의 3차원 유한요소 모델링을 통해 무릎관절의 파손을 평가하여, 임상적 적용 가능성을 높입니다.",
         "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=JAKO200919061729362"
        ],
        [
         "3",
         "article",
         "삼차원 전산화 단층 촬영을 이용한 한국인의 무릎뼈-넙다리뼈 관절 정렬의 분석",
         "This study is to analyse the normal patellofemoral alignment related to anterior knee pain using three dimensional computed tomography(3D CT) in koreans. The study includes 180 knees, 45 men and 45 women which had no history of anterior knee pain and no abnormal finding of malalignment by physical examination. The mean age was 42.2 years (24～66). 3D CT scanning performed in 15˚ of knee flexion with the quadriceps muscle relaxed. Patellofemoral alignment was evaluated by measuring sulcus angle, congruence angle, lateral patellofemoral angle, condyle-patellar angle, condyle-lateral angle. The data are expressed as mean±SD. Statistical evaluations were carried out by paired ｔ-test. p&lt;0.05 was considered significant. The obtained results were as follows. 1. The range in measurements of sulcus angle, between both femoral facets, was 149.4˚±9.74 in men and 145.97˚±8.94 in women. There were no significant differences between the right and left side but showed a higher value in women (p&lt;0.05). 2. The range in measurements of congruence angle, between halving sulcus angle and line between sulcus and inferior dome of patella, was 12.63˚±22.79 in men and 12.08˚±19.64 in women. There were no significant differences between the right and left side or between women and men. 3. The range in measurements of lateral patellofemoral angle, between lateral patellar facet and line over highest part of both condyles, was 9.92˚±6.03 in men and 8.57˚±4.32 in women. There were no significant differences between the right and left side or between women and men. 4. The range in measurements of condyle-patellar angle, (a) lateral facet between lateral patellar facet and line over posterior condyles, was 14.25˚±7.12 in men and 11.84˚±4.80 in women. (b) patellar axis between longest line in patellar major axis and line over posterior condyles, was -8.51˚±7.73 in men and -10.62˚±6.11 in women. There were no significant differences between the right and left side but showed a lower value in ",
         "56.01815",
         "이 연구는 한국인의 무릎뼈-넙다리뼈 관절 정렬을 분석하여, 무릎 통증의 원인을 규명하고 치료 방법을 개선하는 데 기여할 수 있습니다.",
         "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=DIKO&cn=DIKO0011212202"
        ],
        [
         "4",
         "article",
         "한국인의 유증상 무릎 골관절염의 위험요인에 관한 연구",
         "Objective: To investigate the risk factors for symptomatic knee osteoarthritis (OA) in Koreans Methods: A total of 1,194 persons consisting of 588 men and 606 women (mean age±SD, 48.9±14.0 years) were enrolled in rural and urban areas or in a hospital of Korea between september 2000 and august 2001. All participants were interviewed about symptoms of knee OA and possible risk factors including age, sex, occupation, body mass index (BMI), smoking, age of menarche, menopause and hormone replacement therapy and examined. Knee radiograph was obtained in all participants with knee symptoms. Symptomatic knee OA was defined according to clinical criteria or clinical and radiographic criteria for classification of osteoarthritis of the knee by Altman. Results: Of 1,194 participants, symptomatic knee OA was found in 189 persons (15.8%) and multivariate analysis showed that female (OR=5.66, 95% CI 3.42∼9.38), aging (OR=1.10, 95% CI 1.08∼1.12), living in rural area (OR=3.83, 95% CI 2.27∼6.45) and BMI over 25 kg/m<SUP>2</SUP> (OR=2.26, 95% CI 1.42∼3.59) were risk factors. Age (older than 70 years, OR=1.08, 95% CI 1.04∼1.12) and living in rural area (OR=5.39, 05% CI 1.94∼14.96) were associated with symptomatic knee OA in men and age (older than 40 years, OR=1.11, 95% CI 1.07∼1.16), living in rural area (OR=2.46, 95% CI 1.17∼5.17), and BMI over 25 kg/m<SUP>2</SUP> (OR=3.45, 95% CI 1.63∼7.29) in women. Conclusion: The risk factors for symptomatic knee OA were aging, female, living in rural area and high BMI in Koreans.",
         "54.529846",
         "이 연구는 한국인에서 무릎 골관절염의 위험요인을 분석하여, 무릎관절 건강을 개선하기 위한 예방적 접근을 제시합니다.",
         "http://click.ndsl.kr/servlet/OpenAPIDetailView?keyValue=05787966&target=NART&cn=NART50290548"
        ]
       ],
       "shape": {
        "columns": 6,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>구분</th>\n",
       "      <th>제목</th>\n",
       "      <th>설명</th>\n",
       "      <th>점수</th>\n",
       "      <th>추천 사유</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>article</td>\n",
       "      <td>한국인의 3차원 무릎 관절 모델 구축 및 형상 측정</td>\n",
       "      <td>It is necessary to have a model that describes...</td>\n",
       "      <td>92.397377</td>\n",
       "      <td>이 연구는 한국인의 무릎관절 모델을 구축하고 형상을 측정하여, 한국인에 적합한 인공...</td>\n",
       "      <td>http://click.ndsl.kr/servlet/OpenAPIDetailView...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dataset</td>\n",
       "      <td>무릎 인공관절 형상 설계에 활용할 수 있는 한국인 남녀 무릎 관절의 형상 및 치수 ...</td>\n",
       "      <td>1. 관절면 영상 생성  한국인의 무릎 인공관절 형상 설계에 활용할 수 있는 남녀 ...</td>\n",
       "      <td>62.567184</td>\n",
       "      <td>이 연구는 한국인 남녀의 무릎 관절 형상 및 치수 데이터를 제작하여, 인공관절 형상...</td>\n",
       "      <td>https://dk.kisti.re.kr/?q=node/9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>article</td>\n",
       "      <td>자기공명영상 기반 3차원 유한요소모델링을 통한 무릎관절의 파손평가</td>\n",
       "      <td>본 연구에서는 먼저 완전 신전상태의 병변이 없는 26세 남자의 자기공명영상이미지를 ...</td>\n",
       "      <td>58.633949</td>\n",
       "      <td>이 연구는 자기공명영상 기반의 3차원 유한요소 모델링을 통해 무릎관절의 파손을 평가...</td>\n",
       "      <td>http://click.ndsl.kr/servlet/OpenAPIDetailView...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>article</td>\n",
       "      <td>삼차원 전산화 단층 촬영을 이용한 한국인의 무릎뼈-넙다리뼈 관절 정렬의 분석</td>\n",
       "      <td>This study is to analyse the normal patellofem...</td>\n",
       "      <td>56.018150</td>\n",
       "      <td>이 연구는 한국인의 무릎뼈-넙다리뼈 관절 정렬을 분석하여, 무릎 통증의 원인을 규명...</td>\n",
       "      <td>http://click.ndsl.kr/servlet/OpenAPIDetailView...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>article</td>\n",
       "      <td>한국인의 유증상 무릎 골관절염의 위험요인에 관한 연구</td>\n",
       "      <td>Objective: To investigate the risk factors for...</td>\n",
       "      <td>54.529846</td>\n",
       "      <td>이 연구는 한국인에서 무릎 골관절염의 위험요인을 분석하여, 무릎관절 건강을 개선하기...</td>\n",
       "      <td>http://click.ndsl.kr/servlet/OpenAPIDetailView...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        구분                                                 제목  \\\n",
       "0  article                       한국인의 3차원 무릎 관절 모델 구축 및 형상 측정   \n",
       "1  dataset  무릎 인공관절 형상 설계에 활용할 수 있는 한국인 남녀 무릎 관절의 형상 및 치수 ...   \n",
       "2  article               자기공명영상 기반 3차원 유한요소모델링을 통한 무릎관절의 파손평가   \n",
       "3  article         삼차원 전산화 단층 촬영을 이용한 한국인의 무릎뼈-넙다리뼈 관절 정렬의 분석   \n",
       "4  article                      한국인의 유증상 무릎 골관절염의 위험요인에 관한 연구   \n",
       "\n",
       "                                                  설명         점수  \\\n",
       "0  It is necessary to have a model that describes...  92.397377   \n",
       "1  1. 관절면 영상 생성  한국인의 무릎 인공관절 형상 설계에 활용할 수 있는 남녀 ...  62.567184   \n",
       "2  본 연구에서는 먼저 완전 신전상태의 병변이 없는 26세 남자의 자기공명영상이미지를 ...  58.633949   \n",
       "3  This study is to analyse the normal patellofem...  56.018150   \n",
       "4  Objective: To investigate the risk factors for...  54.529846   \n",
       "\n",
       "                                               추천 사유  \\\n",
       "0  이 연구는 한국인의 무릎관절 모델을 구축하고 형상을 측정하여, 한국인에 적합한 인공...   \n",
       "1  이 연구는 한국인 남녀의 무릎 관절 형상 및 치수 데이터를 제작하여, 인공관절 형상...   \n",
       "2  이 연구는 자기공명영상 기반의 3차원 유한요소 모델링을 통해 무릎관절의 파손을 평가...   \n",
       "3  이 연구는 한국인의 무릎뼈-넙다리뼈 관절 정렬을 분석하여, 무릎 통증의 원인을 규명...   \n",
       "4  이 연구는 한국인에서 무릎 골관절염의 위험요인을 분석하여, 무릎관절 건강을 개선하기...   \n",
       "\n",
       "                                                 URL  \n",
       "0  http://click.ndsl.kr/servlet/OpenAPIDetailView...  \n",
       "1                   https://dk.kisti.re.kr/?q=node/9  \n",
       "2  http://click.ndsl.kr/servlet/OpenAPIDetailView...  \n",
       "3  http://click.ndsl.kr/servlet/OpenAPIDetailView...  \n",
       "4  http://click.ndsl.kr/servlet/OpenAPIDetailView...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_id = 'JAKO200411922932805'\n",
    "input_category = 'article'\n",
    "\n",
    "# input_id = 'b37f0c9413eeb7c45f6fe31cbe3a41ef'\n",
    "# input_category = 'dataset'\n",
    "\n",
    "print('[input_id]\\n', input_id)\n",
    "\n",
    "res = graph.invoke({\n",
    "    'input_id': input_id,\n",
    "    'input_category': input_category,\n",
    "})\n",
    "\n",
    "display(res['result_df'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
